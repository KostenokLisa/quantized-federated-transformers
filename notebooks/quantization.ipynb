{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ji1iLhW2eLC"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PRpKL7j9PrB"
      },
      "outputs": [],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWOj0qDS9Tit"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTnMHgBt-LE5"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTQFEZAR9ULB"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.12.0\n",
        "!pip install torchtext==0.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLyH5koG9XAT"
      },
      "outputs": [],
      "source": [
        "!pip install torchdata==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QX9Exbj89Y_n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import wget \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import transformers as ppb\n",
        "import random\n",
        "import warnings\n",
        "import math\n",
        "import copy\n",
        "from packaging import version\n",
        "from torch import Tensor, nn\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dlv7x0JY9bxf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oraovivw3hkC"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W3lSQcdK3xrl"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import Multi30k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aysbyIM64C_T"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MarianConfig, PreTrainedModel\n",
        "from transformers.modeling_outputs import BaseModelOutput, BaseModelOutputWithPastAndCrossAttentions, Seq2SeqModelOutput, Seq2SeqLMOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_mRLez4RNO",
        "outputId": "dc6a9227-74f7-40e0-d7a5-9691ec1f25f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dBvrZ5vi4RNP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/HBFPEmulator/getting_started\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "04MMLDsi4RNP"
      },
      "outputs": [],
      "source": [
        "from bfp_ops import BFPLinear, BFPConv2d, unpack_bfp_args, _get_bfp_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WnGdS_Wp4izs"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5G-bJO4t8-eP"
      },
      "outputs": [],
      "source": [
        "from transformers.models.marian.modeling_marian import _expand_mask, _make_causal_mask, shift_tokens_right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o4_9YA1r9JKh"
      },
      "outputs": [],
      "source": [
        "from transformers.models.marian.modeling_marian import MarianSinusoidalPositionalEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iZE_9UrEsr-M"
      },
      "outputs": [],
      "source": [
        "from transformers.activations import get_activation, ACT2FN, SiLUActivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJ57Kbz8Dlj"
      },
      "source": [
        "## Activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZydXEjbODM2"
      },
      "source": [
        "## Baseline for MT + utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ-R5o4f-CDP",
        "outputId": "9a867e8d-078f-4e89-aa59-b06c44ecf6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 29001\n",
            "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n"
          ]
        }
      ],
      "source": [
        "train_iter = Multi30k(split=\"train\")\n",
        "\n",
        "# torchtext.datasets.DatasetName yield exhaustible IterableDataset.\n",
        "# To fix this we convert our dataset to a list.\n",
        "train_data = list(train_iter)\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSqxcjAI-F1w",
        "outputId": "f606b09a-1565-4eee-e99c-c23c0b103271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test examples: 1000\n",
            "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.', 'A man in an orange hat starring at something.')\n"
          ]
        }
      ],
      "source": [
        "test_iter = Multi30k(split=\"test\")\n",
        "test_data = list(test_iter)\n",
        "print(f\"Number of test examples: {len(test_data)}\")\n",
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YpWSsmZk-QTZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "51bfd5b234134232956e21c26e73126f",
            "4c45bc4717414399bc81723a44686790",
            "27a8106b25ea455c8fe216120e6a57a5",
            "337991df54304c36b610358c254e34aa",
            "feb5b17c9f044553965f5ef336507e46",
            "d57b60aea703412aac5108dc28068843",
            "19886508f6e144b39169545c111ff27c",
            "0cfa8bcaf9704ac38b2d2a87ab258038",
            "79055e18d1c34da4897c4fa0ee12a748",
            "d039378b2abd4443ac9fe52f5785f8a2",
            "8569046b89b749c9a46c1013a1bfe778",
            "49890aa276264c9d85ce1afb2c0ce05b",
            "c95e7babd202407091c7d721fd9c74b8",
            "e0d243863c2d4f2797536872ed0e036f",
            "108f378d3abc439c8d077b54b3b7dca9",
            "684caa89129e41cfb89ad060d37f6915",
            "500fbe26b00140a0be488f23f615c1ab",
            "d9158ee2970648b69e99cad5c072eb24",
            "616281f01c5a4c71814c2a0f0678b255",
            "bb7bfcf885af4abca77fdd91a291aea5",
            "a3db0f7ba34e44b7b213dc3b489adf11",
            "ad9542744438441ab03d3406ce251fa8",
            "1c311de6717a493b9803e5d41c1343a5",
            "528d89c3b91b4276b48265f6b0a2c35c",
            "00417242bb7040659e061372d12d3191",
            "9ba1b4fdb7c044aa999c7f6fab74413e",
            "d7bbb53410b84c2189cd10ca9a065bf3",
            "f4b7ed77739a43d5a937e84db522736b",
            "893b8b912ab44bf6903d49688e177727",
            "16d3f14bfaa2402f94559e35ac3e08c7",
            "bf31ae3461504e56800221b04a946f6f",
            "6ebf6e1934604cd2be1041310ef9ed6e",
            "1d5861e9d43143cca0cdf6fe10ada649",
            "3db799a92191454ab8dae7998b64682f",
            "dbd4dcdfc0e7454c9e58e6767377d6b8",
            "55ff404bf1d648c2915cc64ed3123421",
            "8acd2902450d46b2b2bb1809c7ffcf02",
            "12461a9b9fc24b57a07299691f9d2c01",
            "b00561b581814e14923ea5525889192a",
            "4af0a67087fb45a08d21c8517a8e8330",
            "a8eed31a1fce472682175de317ca5292",
            "e6861e402d49461f8b96ce3ef6e85629",
            "446f3e0cdae34d85af8390b82012b06c",
            "15f70f14867446faa969e94fc24c2b3e",
            "ca5fd3d83af24854b3e2e544abd34223",
            "f169a2136b3e440eb3bfe5f9bce3735b",
            "4fd52fd5768f4f46a76f67c41afd3b66",
            "3ec789dcd62b422b8e32688b1b277f2c",
            "0575333b280c4c6e9509a6160dedf7fb",
            "fc61dcc864514b7ba555e044bb0aa431",
            "50ee9cfab9794a19add7e0eded0848de",
            "8975becc3d6c495eab246ff0f7b88be4",
            "8b207c568ed64bc38e9eaa2efe8485f9",
            "a7bad1ffea71460baac71c2580330633",
            "ee21f9758a744955b21af99d6e7c11b0",
            "44ee1371882a42c2b1f37220c83fe43c",
            "612eb71c82d14f58ab84003ff8cf262b",
            "af23a4b7a3594ceab8c0e33450ee91ac",
            "df1cfce03e164961bcad89cc48fa3edd",
            "fc5851a3e1ef49aead41373566733c83",
            "a766dd83ea6d440c81f4df7b6cb88af9",
            "714e48cb5bfd43f0b66c40b5a4b96b1f",
            "6fb24b34e67244deb498bc92e6d37f97",
            "6762aae638d14714947a088c53dda63b",
            "b950cf64cb1a439fb4b66c1b78a14e56",
            "b3275f6528be49a8b92c6e7cb3084623"
          ]
        },
        "outputId": "d37e57fb-986b-43b3-bcb9-69916a204878"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51bfd5b234134232956e21c26e73126f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49890aa276264c9d85ce1afb2c0ce05b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c311de6717a493b9803e5d41c1343a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading target.spm:   0%|          | 0.00/750k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3db799a92191454ab8dae7998b64682f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca5fd3d83af24854b3e2e544abd34223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/284M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44ee1371882a42c2b1f37220c83fe43c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = 'Helsinki-NLP/opus-mt-de-en'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "native_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QaGi59LsAWf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd964dee-c229-4e54-cb0b-f29b6105672b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available!\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "native_model = native_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_UtgK98AZWG",
        "outputId": "f9ba4adf-2c1b-4f04-9ee7-973485108ab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MarianMTModel(\n",
              "  (model): MarianModel(\n",
              "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
              "    (encoder): MarianEncoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): MarianDecoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=58101, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "native_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "L8meVwYb8ZRb"
      },
      "outputs": [],
      "source": [
        "src_train_raw = []\n",
        "dst_train_raw = []\n",
        "for line in train_data:\n",
        "    src_train_raw.append(line[1].lower())\n",
        "    dst_train_raw.append(line[0].lower())  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "njcLXNtn8ZRc"
      },
      "outputs": [],
      "source": [
        "src_val_raw = []\n",
        "dst_val_raw = []\n",
        "for line in test_data:\n",
        "    src_val_raw.append(line[1].lower())\n",
        "    dst_val_raw.append(line[0].lower())  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcIEs7868ZRc",
        "outputId": "a1f7b6e8-a360-4c95-f0b9-38e9c6f6b1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['two young, white males are outside near many bushes.', 'several men in hard hats are operating a giant pulley system.', 'a little girl climbing into a wooden playhouse.', 'a man in a blue shirt is standing on a ladder cleaning a window.', 'two men are at the stove preparing food.', 'a man in green holds a guitar while the other man observes his shirt.', 'a man is smiling at a stuffed lion', 'a trendy girl talking on her cellphone while gliding slowly down the street.', 'a woman with a large purse is walking by a gate.', 'boys dancing on poles in the middle of the night.']\n",
            "['zwei junge weiße männer sind im freien in der nähe vieler büsche.', 'mehrere männer mit schutzhelmen bedienen ein antriebsradsystem.', 'ein kleines mädchen klettert in ein spielhaus aus holz.', 'ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster.', 'zwei männer stehen am herd und bereiten essen zu.', 'ein mann in grün hält eine gitarre, während der andere mann sein hemd ansieht.', 'ein mann lächelt einen ausgestopften löwen an.', 'ein schickes mädchen spricht mit dem handy während sie langsam die straße entlangschwebt.', 'eine frau mit einer großen geldbörse geht an einem tor vorbei.', 'jungen tanzen mitten in der nacht auf pfosten.']\n"
          ]
        }
      ],
      "source": [
        "print(src_train_raw[:10])\n",
        "print(dst_train_raw[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uObWkYuS8ZRd"
      },
      "outputs": [],
      "source": [
        "src_train = tokenizer(src_train_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "dest_train = tokenizer(dst_train_raw, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "85yh1Qrm8ZRd"
      },
      "outputs": [],
      "source": [
        "src_val = tokenizer(src_val_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "dest_val = tokenizer(dst_val_raw, padding=True, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "y8rOiSUH8ZRd"
      },
      "outputs": [],
      "source": [
        "def estimate_bleu(model, inp_idx, out_idx, batch_size):\n",
        "    tokenizer_W = WordPunctTokenizer()\n",
        "    with torch.no_grad():\n",
        "        translations = []\n",
        "        inp_idx = inp_idx.to(device)\n",
        "        prev_i = 0\n",
        "        for i in tqdm.notebook.tqdm(range(batch_size, len(inp_idx) + batch_size, batch_size)):\n",
        "            output = model.generate(inp_idx[prev_i:i]).cpu()\n",
        "            prev_i = i\n",
        "            translations.extend(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
        "        actual = tokenizer.batch_decode(out_idx, skip_special_tokens=True)\n",
        "        return corpus_bleu(\n",
        "            [[tokenizer_W.tokenize(ref)] for ref in actual],\n",
        "            [tokenizer_W.tokenize(trans.lower()) for trans in translations],\n",
        "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
        "            ) * 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(native_model.config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPFlNXCJhBix",
        "outputId": "f7925444-b9ea-4a58-9afc-7ea090c32ef5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      58100\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 58100,\n",
            "  \"decoder_vocab_size\": 58101,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 58100,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.21.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 58101\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFZTnI1g8e7D"
      },
      "source": [
        "## Quantized model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = MarianConfig(activation_dropout=native_model.config.activation_dropout,\n",
        "activation_function=native_model.config.activation_function,\n",
        "attention_dropout=native_model.config.attention_dropout,\n",
        "classifier_dropout=native_model.config.classifier_dropout,\n",
        "d_model=native_model.config.d_model,\n",
        "decoder_attention_heads=native_model.config.decoder_attention_heads,\n",
        "decoder_ffn_dim=native_model.config.decoder_ffn_dim,\n",
        "decoder_layerdrop=native_model.config.decoder_layerdrop,\n",
        "decoder_layers=native_model.config.decoder_layers,\n",
        "decoder_start_token_id=native_model.config.decoder_start_token_id,\n",
        "decoder_vocab_size=native_model.config.decoder_vocab_size,\n",
        "dropout=native_model.config.dropout,\n",
        "encoder_attention_heads=native_model.config.encoder_attention_heads,\n",
        "encoder_ffn_dim=native_model.config.encoder_ffn_dim,\n",
        "encoder_layerdrop=native_model.config.encoder_layerdrop,\n",
        "encoder_layers=native_model.config.encoder_layers,\n",
        "eos_token_id=native_model.config.eos_token_id,\n",
        "forced_eos_token_id=native_model.config.forced_eos_token_id,\n",
        "init_std=native_model.config.init_std,\n",
        "is_encoder_decoder=native_model.config.is_encoder_decoder,\n",
        "max_position_embeddings=native_model.config.max_position_embeddings,\n",
        "model_type=native_model.config.model_type,\n",
        "num_hidden_layers=native_model.config.num_hidden_layers,\n",
        "pad_token_id=native_model.config.pad_token_id,\n",
        "scale_embedding=native_model.config.scale_embedding,\n",
        "share_encoder_decoder_embeddings=native_model.config.share_encoder_decoder_embeddings,\n",
        "transformers_version=native_model.config.transformers_version,\n",
        "use_cache=native_model.config.use_cache,\n",
        "vocab_size=native_model.config.vocab_size)"
      ],
      "metadata": {
        "id": "0lCaeZe4JCig"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BFPbmm(mat1, mat2, bfp_args={}):\n",
        "    if bfp_args[\"num_format\"] == \"bfp\":\n",
        "        op = _get_bfp_op(torch.bmm, \"bmm\", bfp_args)\n",
        "    else:\n",
        "        op = torch.bmm\n",
        "    return op(mat1, mat2)"
      ],
      "metadata": {
        "id": "lNkhA3U78pqh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "MLia4Wat22rl"
      },
      "outputs": [],
      "source": [
        "class BFPMarianAttention(nn.Module):\n",
        "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim: int,\n",
        "        num_heads: int,\n",
        "        dropout: float = 0.0,\n",
        "        is_decoder: bool = False,\n",
        "        bias: bool = True,\n",
        "        bfp_args={}\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.bfp_args = bfp_args\n",
        "\n",
        "        if (self.head_dim * num_heads) != self.embed_dim:\n",
        "            raise ValueError(\n",
        "                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim}\"\n",
        "                f\" and `num_heads`: {num_heads}).\"\n",
        "            )\n",
        "        self.scaling = self.head_dim**-0.5\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "        self.k_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.v_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.q_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.out_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "\n",
        "\n",
        "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
        "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        key_value_states: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        output_attentions: bool = False\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
        "\n",
        "        # if key_value_states are provided this layer is used as a cross-attention layer\n",
        "        # for the decoder\n",
        "        is_cross_attention = key_value_states is not None\n",
        "\n",
        "        bsz, tgt_len, _ = hidden_states.size()\n",
        "\n",
        "        # get query proj\n",
        "        query_states = self.q_proj(hidden_states) * self.scaling\n",
        "        # get key, value proj\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_states = past_key_value[0]\n",
        "            value_states = past_key_value[1]\n",
        "        elif is_cross_attention:\n",
        "            # cross_attentions\n",
        "            key_states = self._shape(self.k_proj(key_value_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(key_value_states), -1, bsz)\n",
        "        elif past_key_value is not None:\n",
        "            # reuse k, v, self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "            key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
        "            value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
        "        else:\n",
        "            # self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            past_key_value = (key_states, value_states)\n",
        "\n",
        "        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n",
        "        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
        "        key_states = key_states.view(*proj_shape)\n",
        "        value_states = value_states.view(*proj_shape)\n",
        "\n",
        "        src_len = key_states.size(1)\n",
        "        attn_weights = BFPbmm(query_states, key_states.transpose(1, 2), self.bfp_args)\n",
        "\n",
        "        if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
        "            raise ValueError(\n",
        "                f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is\"\n",
        "                f\" {attn_weights.size()}\"\n",
        "            )\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
        "                raise ValueError(\n",
        "                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        if layer_head_mask is not None:\n",
        "            if layer_head_mask.size() != (self.num_heads,):\n",
        "                raise ValueError(\n",
        "                    f\"Head mask for a single layer should be of size {(self.num_heads,)}, but is\"\n",
        "                    f\" {layer_head_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = layer_head_mask.view(1, -1, 1, 1) * attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if output_attentions:\n",
        "            attn_weights_reshaped = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights_reshaped.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "        else:\n",
        "            attn_weights_reshaped = None\n",
        "\n",
        "        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n",
        "        attn_output = BFPbmm(attn_probs, value_states, self.bfp_args)\n",
        "\n",
        "        if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
        "            raise ValueError(\n",
        "                f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is\"\n",
        "                f\" {attn_output.size()}\"\n",
        "            )\n",
        "\n",
        "        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n",
        "        attn_output = attn_output.transpose(1, 2)\n",
        "\n",
        "        attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)\n",
        "\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "        return attn_output, attn_weights_reshaped, past_key_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "HE95byLX0x4v"
      },
      "outputs": [],
      "source": [
        "class BFPMarianEncoderLayer(nn.Module):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__()\n",
        "        # self.embed_dim = config.d_model\n",
        "        self.embed_dim = 512\n",
        "        self.self_attn = BFPMarianAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=8,\n",
        "            dropout=0.0,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.dropout = 0.1\n",
        "\n",
        "        self.activation_fn = ACT2FN[\"swish\"]\n",
        "        self.activation_dropout = 0.0\n",
        "        self.fc1 = BFPLinear(self.embed_dim, 2048, **bfp_args)\n",
        "        self.fc2 = BFPLinear(2048, self.embed_dim, **bfp_args)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.FloatTensor,\n",
        "        attention_mask: torch.FloatTensor,\n",
        "        layer_head_mask: torch.FloatTensor,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[torch.FloatTensor]]:\n",
        "      \n",
        "        residual = hidden_states\n",
        "        hidden_states, attn_weights, _ = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        if hidden_states.dtype == torch.float16 and (\n",
        "            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n",
        "        ):\n",
        "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
        "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (attn_weights,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wPq3y327czp-"
      },
      "outputs": [],
      "source": [
        "class BFPMarianPreTrainedModel(PreTrainedModel):\n",
        "    # config_class = MarianConfig\n",
        "    base_model_prefix = \"model\"\n",
        "    supports_gradient_checkpointing = True\n",
        "\n",
        "    def _init_weights(self, module: Union[nn.Linear, nn.Embedding, MarianSinusoidalPositionalEmbedding]):\n",
        "        std = 0.02\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, MarianSinusoidalPositionalEmbedding):\n",
        "            pass\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "\n",
        "    def _set_gradient_checkpointing(self, module, value=False):\n",
        "        if isinstance(module, (BFPMarianDecoder, BFPMarianEncoder)):\n",
        "            module.gradient_checkpointing = value\n",
        "\n",
        "    @property\n",
        "    def dummy_inputs(self):\n",
        "        pad_token = 58100\n",
        "        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n",
        "        dummy_inputs = {\n",
        "            \"attention_mask\": input_ids.ne(pad_token),\n",
        "            \"input_ids\": input_ids,\n",
        "            \"decoder_input_ids\": input_ids,\n",
        "        }\n",
        "        return dummy_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "fjtwQk3VO0xx"
      },
      "outputs": [],
      "source": [
        "class BFPMarianEncoder(BFPMarianPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer is a\n",
        "    [`MarianEncoderLayer`].\n",
        "    Args:\n",
        "        config: MarianConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: MarianConfig, embed_tokens: Optional[nn.Embedding] = None, bfp_args={}):\n",
        "        super().__init__(config, bfp_args)\n",
        "\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.encoder_layerdrop\n",
        "\n",
        "        embed_dim = config.d_model\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_source_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens = embed_tokens\n",
        "        else:\n",
        "            self.embed_tokens = nn.Embedding(config.vocab_size, embed_dim, self.padding_idx)\n",
        "\n",
        "        self.embed_positions = MarianSinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings, embed_dim, self.padding_idx\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BFPMarianEncoderLayer(config, bfp_args) for _ in range(config.encoder_layers)])\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutput]:\n",
        "   \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
        "\n",
        "        embed_pos = self.embed_positions(input_shape)\n",
        "\n",
        "        hidden_states = inputs_embeds + embed_pos\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        # expand attention_mask\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            attention_mask = _expand_mask(attention_mask, inputs_embeds.dtype)\n",
        "\n",
        "        encoder_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        # check if head_mask has a correct number of layers specified if desired\n",
        "        if head_mask is not None:\n",
        "            assert head_mask.size()[0] == (\n",
        "                len(self.layers)\n",
        "            ), f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"\n",
        "        for idx, encoder_layer in enumerate(self.layers):\n",
        "            if output_hidden_states:\n",
        "                encoder_states = encoder_states + (hidden_states,)\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            dropout_probability = random.uniform(0, 1)\n",
        "            if self.training and (dropout_probability < self.layerdrop):  # skip the layer\n",
        "                layer_outputs = (None, None)\n",
        "            else:\n",
        "                if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                    def create_custom_forward(module):\n",
        "                        def custom_forward(*inputs):\n",
        "                            return module(*inputs, output_attentions)\n",
        "\n",
        "                        return custom_forward\n",
        "\n",
        "                    layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                        create_custom_forward(encoder_layer),\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        (head_mask[idx] if head_mask is not None else None),\n",
        "                    )\n",
        "                else:\n",
        "                    layer_outputs = encoder_layer(\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                        output_attentions=output_attentions,\n",
        "                    )\n",
        "\n",
        "                hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            encoder_states = encoder_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dIgrNG8K7XN3"
      },
      "outputs": [],
      "source": [
        "class BFPMarianDecoderLayer(nn.Module):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.d_model\n",
        "\n",
        "        self.self_attn = BFPMarianAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.dropout = config.dropout\n",
        "        self.activation_fn = ACT2FN[\"swish\"]\n",
        "        self.activation_dropout = config.activation_dropout\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.encoder_attn = BFPMarianAttention(\n",
        "            self.embed_dim,\n",
        "            config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.encoder_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.fc1 = BFPLinear(self.embed_dim, config.decoder_ffn_dim, **bfp_args)\n",
        "        self.fc2 = BFPLinear(config.decoder_ffn_dim, self.embed_dim, **bfp_args)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        use_cache: Optional[bool] = True,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
        "      \n",
        "        residual = hidden_states\n",
        "\n",
        "        # Self Attention\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "        # add present self-attn cache to positions 1,2 of present_key_value tuple\n",
        "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        # Cross-Attention Block\n",
        "        cross_attn_present_key_value = None\n",
        "        cross_attn_weights = None\n",
        "        if encoder_hidden_states is not None:\n",
        "            residual = hidden_states\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n",
        "                hidden_states=hidden_states,\n",
        "                key_value_states=encoder_hidden_states,\n",
        "                attention_mask=encoder_attention_mask,\n",
        "                layer_head_mask=cross_attn_layer_head_mask,\n",
        "                past_key_value=cross_attn_past_key_value,\n",
        "                output_attentions=output_attentions,\n",
        "            )\n",
        "            hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "            hidden_states = residual + hidden_states\n",
        "            hidden_states = self.encoder_attn_layer_norm(hidden_states)\n",
        "\n",
        "            # add cross-attn to positions 3,4 of present_key_value tuple\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        # Fully Connected\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (self_attn_weights, cross_attn_weights)\n",
        "\n",
        "        if use_cache:\n",
        "            outputs += (present_key_value,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "-JiyfjCVoIEa"
      },
      "outputs": [],
      "source": [
        "class BFPMarianDecoder(BFPMarianPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer decoder consisting of *config.decoder_layers* layers. Each layer is a [`MarianDecoderLayer`]\n",
        "    Args:\n",
        "        config: MarianConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: MarianConfig, embed_tokens: Optional[nn.Embedding] = None, bfp_args={}):\n",
        "        super().__init__(config, bfp_args)\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.decoder_layerdrop\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_target_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens = embed_tokens\n",
        "        else:\n",
        "            self.embed_tokens = nn.Embedding(config.decoder_vocab_size, config.d_model, self.padding_idx)\n",
        "\n",
        "        self.embed_positions = MarianSinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings, config.d_model, self.padding_idx\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BFPMarianDecoderLayer(config, bfp_args) for _ in range(config.decoder_layers)])\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    # Copied from transformers.models.bart.modeling_bart.BartDecoder._prepare_decoder_attention_mask\n",
        "    def _prepare_decoder_attention_mask(self, attention_mask, input_shape, inputs_embeds, past_key_values_length):\n",
        "        # create causal mask\n",
        "        # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "        combined_attention_mask = None\n",
        "        if input_shape[-1] > 1:\n",
        "            combined_attention_mask = _make_causal_mask(\n",
        "                input_shape, inputs_embeds.dtype, past_key_values_length=past_key_values_length\n",
        "            ).to(inputs_embeds.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            expanded_attn_mask = _expand_mask(attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n",
        "            combined_attention_mask = (\n",
        "                expanded_attn_mask if combined_attention_mask is None else expanded_attn_mask + combined_attention_mask\n",
        "            )\n",
        "\n",
        "        return combined_attention_mask\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
        "       \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
        "\n",
        "        attention_mask = self._prepare_decoder_attention_mask(\n",
        "            attention_mask, input_shape, inputs_embeds, past_key_values_length\n",
        "        )\n",
        "\n",
        "        # expand encoder attention mask\n",
        "        if encoder_hidden_states is not None and encoder_attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            encoder_attention_mask = _expand_mask(encoder_attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n",
        "\n",
        "        # embed positions\n",
        "        positions = self.embed_positions(input_shape, past_key_values_length)\n",
        "\n",
        "        hidden_states = inputs_embeds + positions\n",
        "\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        # decoder layers\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attns = () if output_attentions else None\n",
        "        all_cross_attentions = () if (output_attentions and encoder_hidden_states is not None) else None\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "\n",
        "        # check if head_mask/cross_attn_head_mask has a correct number of layers specified if desired\n",
        "        for attn_mask, mask_name in zip([head_mask, cross_attn_head_mask], [\"head_mask\", \"cross_attn_head_mask\"]):\n",
        "            if attn_mask is not None:\n",
        "                assert attn_mask.size()[0] == (len(self.layers)), (\n",
        "                    f\"The `{mask_name}` should be specified for {len(self.layers)} layers, but it is for\"\n",
        "                    f\" {head_mask.size()[0]}.\"\n",
        "                )\n",
        "        for idx, decoder_layer in enumerate(self.layers):\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states += (hidden_states,)\n",
        "            dropout_probability = random.uniform(0, 1)\n",
        "            if self.training and (dropout_probability < self.layerdrop):\n",
        "                continue\n",
        "\n",
        "            past_key_value = past_key_values[idx] if past_key_values is not None else None\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                if use_cache:\n",
        "                    # logger.warning(\n",
        "                        # \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                    # )\n",
        "                    use_cache = False\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        # None for past_key_value\n",
        "                        return module(*inputs, output_attentions, use_cache)\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(decoder_layer),\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    head_mask[idx] if head_mask is not None else None,\n",
        "                    cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None,\n",
        "                    None,\n",
        "                )\n",
        "            else:\n",
        "\n",
        "                layer_outputs = decoder_layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask=attention_mask,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    encoder_attention_mask=encoder_attention_mask,\n",
        "                    layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                    cross_attn_layer_head_mask=(\n",
        "                        cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None\n",
        "                    ),\n",
        "                    past_key_value=past_key_value,\n",
        "                    output_attentions=output_attentions,\n",
        "                    use_cache=use_cache,\n",
        "                )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[3 if output_attentions else 1],)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_self_attns += (layer_outputs[1],)\n",
        "\n",
        "                if encoder_hidden_states is not None:\n",
        "                    all_cross_attentions += (layer_outputs[2],)\n",
        "\n",
        "        # add hidden states from the last decoder layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states += (hidden_states,)\n",
        "\n",
        "        next_cache = next_decoder_cache if use_cache else None\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [hidden_states, next_cache, all_hidden_states, all_self_attns, all_cross_attentions]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attns,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NNadqpYZapSt"
      },
      "outputs": [],
      "source": [
        "class BFPMarianModel(BFPMarianPreTrainedModel):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__(config)\n",
        "\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "\n",
        "        # We always use self.shared for token embeddings to ensure compatibility with all marian models\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "        encoder_embed_tokens = decoder_embed_tokens = self.shared\n",
        "\n",
        "        self.encoder = BFPMarianEncoder(config, encoder_embed_tokens, bfp_args)\n",
        "        self.decoder = BFPMarianDecoder(config, decoder_embed_tokens, bfp_args)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        # This will return shared embeddings if they are shared else specific to encoder.\n",
        "        return self.get_encoder().get_input_embeddings()\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self.shared = value\n",
        "            self.encoder.embed_tokens = self.shared\n",
        "            self.decoder.embed_tokens = self.shared\n",
        "        else:  # if not shared only set encoder embeedings\n",
        "            self.encoder.embed_tokens = value\n",
        "\n",
        "    def get_decoder_input_embeddings(self):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`get_decoder_input_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `get_input_embeddings` instead.\"\n",
        "            )\n",
        "        return self.get_decoder().get_input_embeddings()\n",
        "\n",
        "    def set_decoder_input_embeddings(self, value):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`config.share_encoder_decoder_embeddings` is set to `True` meaning the decoder input embeddings \"\n",
        "                \"are shared with the encoder. In order to set the decoder input embeddings, you should simply set \"\n",
        "                \"the encoder input embeddings by calling `set_input_embeddings` with the appropriate embeddings.\"\n",
        "            )\n",
        "        self.decoder.embed_tokens = value\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.decoder\n",
        "\n",
        "    def resize_decoder_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`resize_decoder_token_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `resize_token_embeddings` instead.\"\n",
        "            )\n",
        "\n",
        "        old_embeddings = self.get_decoder_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.set_decoder_input_embeddings(new_embeddings)\n",
        "\n",
        "        model_embeds = self.get_decoder_input_embeddings()\n",
        "\n",
        "        if new_num_tokens is None:\n",
        "            return model_embeds\n",
        "\n",
        "        # Update base model and current model config\n",
        "        self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # Tie weights again if needed\n",
        "        self.tie_weights()\n",
        "\n",
        "        return model_embeds\n",
        "\n",
        "    # @add_start_docstrings_to_model_forward(MARIAN_INPUTS_DOCSTRING)\n",
        "    # @replace_return_docstrings(output_type=Seq2SeqModelOutput, config_class=_CONFIG_FOR_DOC)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Seq2SeqModelOutput:\n",
        "        \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0],\n",
        "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
        "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
        "            )\n",
        "\n",
        "        # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            encoder_hidden_states=encoder_outputs[0],\n",
        "            encoder_attention_mask=attention_mask,\n",
        "            head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return decoder_outputs + encoder_outputs\n",
        "\n",
        "        return Seq2SeqModelOutput(\n",
        "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
        "            past_key_values=decoder_outputs.past_key_values,\n",
        "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
        "            decoder_attentions=decoder_outputs.attentions,\n",
        "            cross_attentions=decoder_outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
        "            encoder_attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "      # @add_start_docstrings(\n",
        "   # \"The Marian Model with a language modeling head. Can be used for summarization.\", MARIAN_START_DOCSTRING\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VaqZqURA972w"
      },
      "outputs": [],
      "source": [
        "class BFPMarianMTModel(BFPMarianPreTrainedModel):\n",
        "    base_model_prefix = \"model\"\n",
        "    _keys_to_ignore_on_load_missing = [\n",
        "        r\"final_logits_bias\",\n",
        "        r\"encoder.version\",\n",
        "        r\"decoder.version\",\n",
        "        r\"lm_head.weight\",\n",
        "        r\"embed_positions\",\n",
        "    ]\n",
        "\n",
        "    _keys_to_ignore_on_save = [\"model.encoder.embed_positions.weight\", \"model.decoder.embed_positions.weight\"]\n",
        "\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__(config)\n",
        "        self.model = BFPMarianModel(config, bfp_args)\n",
        "\n",
        "        target_vocab_size = config.vocab_size if config.share_encoder_decoder_embeddings else config.decoder_vocab_size\n",
        "        self.register_buffer(\"final_logits_bias\", torch.zeros((1, target_vocab_size)))\n",
        "        self.lm_head = BFPLinear(512, target_vocab_size, bias=False, bfp_args = bfp_args)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.model.get_encoder()\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.get_decoder()\n",
        "\n",
        "    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self._resize_final_logits_bias(new_num_tokens)\n",
        "        return new_embeddings\n",
        "\n",
        "    def _resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        old_embeddings = self.get_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.set_input_embeddings(new_embeddings)\n",
        "\n",
        "        # update config.decoder_vocab_size if embeddings are tied\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # if word embeddings are not tied, make sure that lm head is resized as well\n",
        "        if (\n",
        "            self.config.share_encoder_decoder_embeddings\n",
        "            and self.get_output_embeddings() is not None\n",
        "            and not self.config.tie_word_embeddings\n",
        "        ):\n",
        "            old_lm_head = self.get_output_embeddings()\n",
        "            new_lm_head = self._get_resized_lm_head(old_lm_head, new_num_tokens)\n",
        "            self.set_output_embeddings(new_lm_head)\n",
        "\n",
        "        return self.get_input_embeddings()\n",
        "\n",
        "    def resize_decoder_token_embeddings(self, new_num_tokens):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`resize_decoder_token_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `resize_token_embeddings` instead.\"\n",
        "            )\n",
        "\n",
        "        old_embeddings = self.model.get_decoder_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.model.set_decoder_input_embeddings(new_embeddings)\n",
        "\n",
        "        # if word embeddings are not tied, make sure that lm head is resized as well\n",
        "        if self.get_output_embeddings() is not None and not self.config.tie_word_embeddings:\n",
        "            old_lm_head = self.get_output_embeddings()\n",
        "            new_lm_head = self._get_resized_lm_head(old_lm_head, new_num_tokens)\n",
        "            self.set_output_embeddings(new_lm_head)\n",
        "\n",
        "        model_embeds = self.model.get_decoder_input_embeddings()\n",
        "\n",
        "        if new_num_tokens is None:\n",
        "            return model_embeds\n",
        "\n",
        "        # Update base model and current model config\n",
        "        self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # Tie weights again if needed\n",
        "        self.tie_weights()\n",
        "\n",
        "        self._resize_final_logits_bias(new_num_tokens)\n",
        "\n",
        "        return model_embeds\n",
        "\n",
        "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
        "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
        "        if new_num_tokens <= old_num_tokens:\n",
        "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
        "        else:\n",
        "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
        "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
        "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings: nn.Embedding):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    def tie_weights(self):\n",
        "        \"\"\"\n",
        "        Tie the weights between the input embeddings and the output embeddings.\n",
        "        If the `torchscript` flag is set in the configuration, can't handle parameter sharing so we are cloning the\n",
        "        weights instead.\n",
        "        \"\"\"\n",
        "        output_embeddings = self.get_output_embeddings()\n",
        "        if output_embeddings is not None and getattr(self.config, \"tie_word_embeddings\", True):\n",
        "            # if embeddings are shared this will return shared embeddings otherwise decoder embed_tokens\n",
        "            word_embeddings = self.get_decoder().get_input_embeddings()\n",
        "            self._tie_or_clone_weights(output_embeddings, word_embeddings)\n",
        "\n",
        "        if getattr(self.config, \"is_encoder_decoder\", False) and getattr(self.config, \"tie_encoder_decoder\", False):\n",
        "            if hasattr(self, self.base_model_prefix):\n",
        "                self = getattr(self, self.base_model_prefix)\n",
        "            self._tie_encoder_decoder_weights(self.encoder, self.decoder, self.base_model_prefix)\n",
        "\n",
        "        for module in self.modules():\n",
        "            if hasattr(module, \"_tie_weights\"):\n",
        "                module._tie_weights()\n",
        "\n",
        "    # @add_start_docstrings_to_model_forward(MARIAN_INPUTS_DOCSTRING)\n",
        "    # @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n",
        "    # @add_end_docstrings(MARIAN_GENERATION_EXAMPLE)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Seq2SeqLMOutput:\n",
        "       \n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if labels is not None:\n",
        "            use_cache = False\n",
        "            if decoder_input_ids is None:\n",
        "                decoder_input_ids = shift_tokens_right(\n",
        "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "                )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
        "\n",
        "        masked_lm_loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(lm_logits.view(-1, 58101), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + outputs[1:]\n",
        "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
        "\n",
        "        return Seq2SeqLMOutput(\n",
        "            loss=masked_lm_loss,\n",
        "            logits=lm_logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
        "            decoder_attentions=outputs.decoder_attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
        "            encoder_attentions=outputs.encoder_attentions,\n",
        "        )\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        decoder_input_ids: torch.LongTensor,\n",
        "        past: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        **kwargs,\n",
        "    ) -> Dict:\n",
        "        # cut decoder_input_ids if past is used\n",
        "        if past is not None:\n",
        "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "            \"past_key_values\": past,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"head_mask\": head_mask,\n",
        "            \"decoder_head_mask\": decoder_head_mask,\n",
        "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
        "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
        "        }\n",
        "\n",
        "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
        "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
        "\n",
        "    def adjust_logits_during_generation(self, logits, cur_len):\n",
        "        logits[:, self.config.pad_token_id] = float(\"-inf\")  # never predict pad token.\n",
        "        return logits\n",
        "\n",
        "    @staticmethod\n",
        "    def _reorder_cache(past, beam_idx):\n",
        "        reordered_past = ()\n",
        "        for layer_past in past:\n",
        "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
        "            reordered_past += (\n",
        "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
        "            )\n",
        "        return reordered_past\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "z1dVNe7zB0Ma"
      },
      "outputs": [],
      "source": [
        "# bfp quantization arguments\n",
        "args = {\"num_format\": \"bfp\", \"rounding_mode\": \"stoc\", \"mant_bits\": 8, \n",
        "        \"bfp_tile_size\": 0, \"weight_mant_bits\": 16, \"device\": \"cuda\", \"epsilon\": 1e-8}\n",
        "model = BFPMarianMTModel(config, args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBYE594Erg2"
      },
      "source": [
        "## Quantized model vs basic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_yMPVrKzRNd"
      },
      "source": [
        "Load pretrained MarianMT model from transformers and estimate its score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "MqQdA7W1z7ro"
      },
      "outputs": [],
      "source": [
        "train_ids = dest_train[\"input_ids\"]\n",
        "train_labels = src_train[\"input_ids\"]\n",
        "train_mask = dest_train[\"attention_mask\"] \n",
        "val_ids = dest_val[\"input_ids\"]\n",
        "val_labels = src_val[\"input_ids\"]\n",
        "val_mask = dest_val[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "e1c2156738ed46af9b8f38f59bdaa123",
            "d47faab3db6a4374ac869d20b09815ac",
            "1bb06fcd716949ee82e13ce7b9ddaa02",
            "e441da93bd7944a7b88b5c135ce54720",
            "3f8abdf5655b461981f6aca3b600a78f",
            "745d7428ceed4ee2a91fa616dee4a42c",
            "1aba9c10d3ee41f4a66d3c074004d9d8",
            "3cb2684196124216975b27ab45919396",
            "035fb004e84d4d84b661c2ad321afe0f",
            "56eb2fbed6af402a84986e1b8a767e88",
            "3fa1b7135b394646b08a47b120db55a8"
          ]
        },
        "id": "i5fOOfyLD0XC",
        "outputId": "0cc2ec42-e79e-4f10-cde1-b4f573045d9a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c2156738ed46af9b8f38f59bdaa123"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36.010082881456306"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "estimate_bleu(native_model, val_ids, val_labels, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "42lj7zaO0bF6"
      },
      "outputs": [],
      "source": [
        "torch.save(native_model.state_dict(), \"init.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyDmE9j0JG5E",
        "outputId": "b26f85a1-179b-45aa-fad9-cfefea736f55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BFPMarianMTModel(\n",
              "  (model): BFPMarianModel(\n",
              "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
              "    (encoder): BFPMarianEncoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): BFPMarianDecoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): BFPLinear(in_features=512, out_features=58101, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"init.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "F-e7pBz61uat"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "29d70c79113547df9a7bbccf46912a43",
            "df39a9a22fb14845a81b59a958d863a0",
            "82ee1340cc1742758ff419034027a5ed",
            "d026fe90ddad44f68ac128ee2a0c82c9",
            "38f9602392bb4f74a619f9568a5eab39",
            "2220142aa5f94ffabc832c2942879492",
            "f859742e71124966b3b1dafcc6243f10",
            "e5e37996964240028b44a8ede93d19e8",
            "a4fce34397f54b37903c0ef2440b2956",
            "3b0aeeb2d4a74c24b39dac57c399a020",
            "eea0e3bd63ef47e6a8550dabeea1caa0"
          ]
        },
        "id": "dufp9cA5AsFQ",
        "outputId": "f60a0916-3b48-4675-8535-b85e08ecb2c1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/63 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29d70c79113547df9a7bbccf46912a43"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.42925001018834"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "train_ids = dest_train[\"input_ids\"]\n",
        "train_labels = src_train[\"input_ids\"]\n",
        "train_mask = dest_train[\"attention_mask\"] \n",
        "val_ids = dest_val[\"input_ids\"]\n",
        "val_labels = src_val[\"input_ids\"]\n",
        "val_mask = dest_val[\"attention_mask\"]\n",
        "\n",
        "estimate_bleu(model, val_ids, val_labels, 16) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXXB76okvN2D",
        "outputId": "edf0a948-5efe-4b8b-d6da-a41706f0c6e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(\"init.pth\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "quantization.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51bfd5b234134232956e21c26e73126f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c45bc4717414399bc81723a44686790",
              "IPY_MODEL_27a8106b25ea455c8fe216120e6a57a5",
              "IPY_MODEL_337991df54304c36b610358c254e34aa"
            ],
            "layout": "IPY_MODEL_feb5b17c9f044553965f5ef336507e46"
          }
        },
        "4c45bc4717414399bc81723a44686790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57b60aea703412aac5108dc28068843",
            "placeholder": "​",
            "style": "IPY_MODEL_19886508f6e144b39169545c111ff27c",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "27a8106b25ea455c8fe216120e6a57a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cfa8bcaf9704ac38b2d2a87ab258038",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79055e18d1c34da4897c4fa0ee12a748",
            "value": 42
          }
        },
        "337991df54304c36b610358c254e34aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d039378b2abd4443ac9fe52f5785f8a2",
            "placeholder": "​",
            "style": "IPY_MODEL_8569046b89b749c9a46c1013a1bfe778",
            "value": " 42.0/42.0 [00:00&lt;00:00, 1.57kB/s]"
          }
        },
        "feb5b17c9f044553965f5ef336507e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57b60aea703412aac5108dc28068843": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19886508f6e144b39169545c111ff27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cfa8bcaf9704ac38b2d2a87ab258038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79055e18d1c34da4897c4fa0ee12a748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d039378b2abd4443ac9fe52f5785f8a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8569046b89b749c9a46c1013a1bfe778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49890aa276264c9d85ce1afb2c0ce05b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c95e7babd202407091c7d721fd9c74b8",
              "IPY_MODEL_e0d243863c2d4f2797536872ed0e036f",
              "IPY_MODEL_108f378d3abc439c8d077b54b3b7dca9"
            ],
            "layout": "IPY_MODEL_684caa89129e41cfb89ad060d37f6915"
          }
        },
        "c95e7babd202407091c7d721fd9c74b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500fbe26b00140a0be488f23f615c1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_d9158ee2970648b69e99cad5c072eb24",
            "value": "Downloading config.json: 100%"
          }
        },
        "e0d243863c2d4f2797536872ed0e036f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_616281f01c5a4c71814c2a0f0678b255",
            "max": 1132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb7bfcf885af4abca77fdd91a291aea5",
            "value": 1132
          }
        },
        "108f378d3abc439c8d077b54b3b7dca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3db0f7ba34e44b7b213dc3b489adf11",
            "placeholder": "​",
            "style": "IPY_MODEL_ad9542744438441ab03d3406ce251fa8",
            "value": " 1.11k/1.11k [00:00&lt;00:00, 29.7kB/s]"
          }
        },
        "684caa89129e41cfb89ad060d37f6915": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "500fbe26b00140a0be488f23f615c1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9158ee2970648b69e99cad5c072eb24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "616281f01c5a4c71814c2a0f0678b255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7bfcf885af4abca77fdd91a291aea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3db0f7ba34e44b7b213dc3b489adf11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad9542744438441ab03d3406ce251fa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c311de6717a493b9803e5d41c1343a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_528d89c3b91b4276b48265f6b0a2c35c",
              "IPY_MODEL_00417242bb7040659e061372d12d3191",
              "IPY_MODEL_9ba1b4fdb7c044aa999c7f6fab74413e"
            ],
            "layout": "IPY_MODEL_d7bbb53410b84c2189cd10ca9a065bf3"
          }
        },
        "528d89c3b91b4276b48265f6b0a2c35c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b7ed77739a43d5a937e84db522736b",
            "placeholder": "​",
            "style": "IPY_MODEL_893b8b912ab44bf6903d49688e177727",
            "value": "Downloading source.spm: 100%"
          }
        },
        "00417242bb7040659e061372d12d3191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16d3f14bfaa2402f94559e35ac3e08c7",
            "max": 796845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf31ae3461504e56800221b04a946f6f",
            "value": 796845
          }
        },
        "9ba1b4fdb7c044aa999c7f6fab74413e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebf6e1934604cd2be1041310ef9ed6e",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5861e9d43143cca0cdf6fe10ada649",
            "value": " 778k/778k [00:00&lt;00:00, 4.62MB/s]"
          }
        },
        "d7bbb53410b84c2189cd10ca9a065bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4b7ed77739a43d5a937e84db522736b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893b8b912ab44bf6903d49688e177727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16d3f14bfaa2402f94559e35ac3e08c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf31ae3461504e56800221b04a946f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ebf6e1934604cd2be1041310ef9ed6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5861e9d43143cca0cdf6fe10ada649": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3db799a92191454ab8dae7998b64682f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbd4dcdfc0e7454c9e58e6767377d6b8",
              "IPY_MODEL_55ff404bf1d648c2915cc64ed3123421",
              "IPY_MODEL_8acd2902450d46b2b2bb1809c7ffcf02"
            ],
            "layout": "IPY_MODEL_12461a9b9fc24b57a07299691f9d2c01"
          }
        },
        "dbd4dcdfc0e7454c9e58e6767377d6b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00561b581814e14923ea5525889192a",
            "placeholder": "​",
            "style": "IPY_MODEL_4af0a67087fb45a08d21c8517a8e8330",
            "value": "Downloading target.spm: 100%"
          }
        },
        "55ff404bf1d648c2915cc64ed3123421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8eed31a1fce472682175de317ca5292",
            "max": 768489,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6861e402d49461f8b96ce3ef6e85629",
            "value": 768489
          }
        },
        "8acd2902450d46b2b2bb1809c7ffcf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_446f3e0cdae34d85af8390b82012b06c",
            "placeholder": "​",
            "style": "IPY_MODEL_15f70f14867446faa969e94fc24c2b3e",
            "value": " 750k/750k [00:00&lt;00:00, 6.33MB/s]"
          }
        },
        "12461a9b9fc24b57a07299691f9d2c01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00561b581814e14923ea5525889192a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af0a67087fb45a08d21c8517a8e8330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8eed31a1fce472682175de317ca5292": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6861e402d49461f8b96ce3ef6e85629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "446f3e0cdae34d85af8390b82012b06c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15f70f14867446faa969e94fc24c2b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca5fd3d83af24854b3e2e544abd34223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f169a2136b3e440eb3bfe5f9bce3735b",
              "IPY_MODEL_4fd52fd5768f4f46a76f67c41afd3b66",
              "IPY_MODEL_3ec789dcd62b422b8e32688b1b277f2c"
            ],
            "layout": "IPY_MODEL_0575333b280c4c6e9509a6160dedf7fb"
          }
        },
        "f169a2136b3e440eb3bfe5f9bce3735b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc61dcc864514b7ba555e044bb0aa431",
            "placeholder": "​",
            "style": "IPY_MODEL_50ee9cfab9794a19add7e0eded0848de",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "4fd52fd5768f4f46a76f67c41afd3b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8975becc3d6c495eab246ff0f7b88be4",
            "max": 1273232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b207c568ed64bc38e9eaa2efe8485f9",
            "value": 1273232
          }
        },
        "3ec789dcd62b422b8e32688b1b277f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7bad1ffea71460baac71c2580330633",
            "placeholder": "​",
            "style": "IPY_MODEL_ee21f9758a744955b21af99d6e7c11b0",
            "value": " 1.21M/1.21M [00:00&lt;00:00, 3.96MB/s]"
          }
        },
        "0575333b280c4c6e9509a6160dedf7fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc61dcc864514b7ba555e044bb0aa431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50ee9cfab9794a19add7e0eded0848de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8975becc3d6c495eab246ff0f7b88be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b207c568ed64bc38e9eaa2efe8485f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7bad1ffea71460baac71c2580330633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee21f9758a744955b21af99d6e7c11b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44ee1371882a42c2b1f37220c83fe43c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_612eb71c82d14f58ab84003ff8cf262b",
              "IPY_MODEL_af23a4b7a3594ceab8c0e33450ee91ac",
              "IPY_MODEL_df1cfce03e164961bcad89cc48fa3edd"
            ],
            "layout": "IPY_MODEL_fc5851a3e1ef49aead41373566733c83"
          }
        },
        "612eb71c82d14f58ab84003ff8cf262b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a766dd83ea6d440c81f4df7b6cb88af9",
            "placeholder": "​",
            "style": "IPY_MODEL_714e48cb5bfd43f0b66c40b5a4b96b1f",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "af23a4b7a3594ceab8c0e33450ee91ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fb24b34e67244deb498bc92e6d37f97",
            "max": 297928209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6762aae638d14714947a088c53dda63b",
            "value": 297928209
          }
        },
        "df1cfce03e164961bcad89cc48fa3edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b950cf64cb1a439fb4b66c1b78a14e56",
            "placeholder": "​",
            "style": "IPY_MODEL_b3275f6528be49a8b92c6e7cb3084623",
            "value": " 284M/284M [00:06&lt;00:00, 58.8MB/s]"
          }
        },
        "fc5851a3e1ef49aead41373566733c83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a766dd83ea6d440c81f4df7b6cb88af9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "714e48cb5bfd43f0b66c40b5a4b96b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fb24b34e67244deb498bc92e6d37f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6762aae638d14714947a088c53dda63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b950cf64cb1a439fb4b66c1b78a14e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3275f6528be49a8b92c6e7cb3084623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c2156738ed46af9b8f38f59bdaa123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d47faab3db6a4374ac869d20b09815ac",
              "IPY_MODEL_1bb06fcd716949ee82e13ce7b9ddaa02",
              "IPY_MODEL_e441da93bd7944a7b88b5c135ce54720"
            ],
            "layout": "IPY_MODEL_3f8abdf5655b461981f6aca3b600a78f"
          }
        },
        "d47faab3db6a4374ac869d20b09815ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_745d7428ceed4ee2a91fa616dee4a42c",
            "placeholder": "​",
            "style": "IPY_MODEL_1aba9c10d3ee41f4a66d3c074004d9d8",
            "value": "100%"
          }
        },
        "1bb06fcd716949ee82e13ce7b9ddaa02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3cb2684196124216975b27ab45919396",
            "max": 63,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_035fb004e84d4d84b661c2ad321afe0f",
            "value": 63
          }
        },
        "e441da93bd7944a7b88b5c135ce54720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56eb2fbed6af402a84986e1b8a767e88",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa1b7135b394646b08a47b120db55a8",
            "value": " 63/63 [07:19&lt;00:00,  6.93s/it]"
          }
        },
        "3f8abdf5655b461981f6aca3b600a78f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "745d7428ceed4ee2a91fa616dee4a42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aba9c10d3ee41f4a66d3c074004d9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3cb2684196124216975b27ab45919396": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "035fb004e84d4d84b661c2ad321afe0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56eb2fbed6af402a84986e1b8a767e88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa1b7135b394646b08a47b120db55a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29d70c79113547df9a7bbccf46912a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df39a9a22fb14845a81b59a958d863a0",
              "IPY_MODEL_82ee1340cc1742758ff419034027a5ed",
              "IPY_MODEL_d026fe90ddad44f68ac128ee2a0c82c9"
            ],
            "layout": "IPY_MODEL_38f9602392bb4f74a619f9568a5eab39"
          }
        },
        "df39a9a22fb14845a81b59a958d863a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2220142aa5f94ffabc832c2942879492",
            "placeholder": "​",
            "style": "IPY_MODEL_f859742e71124966b3b1dafcc6243f10",
            "value": "100%"
          }
        },
        "82ee1340cc1742758ff419034027a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e37996964240028b44a8ede93d19e8",
            "max": 63,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4fce34397f54b37903c0ef2440b2956",
            "value": 63
          }
        },
        "d026fe90ddad44f68ac128ee2a0c82c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0aeeb2d4a74c24b39dac57c399a020",
            "placeholder": "​",
            "style": "IPY_MODEL_eea0e3bd63ef47e6a8550dabeea1caa0",
            "value": " 63/63 [00:40&lt;00:00,  1.65it/s]"
          }
        },
        "38f9602392bb4f74a619f9568a5eab39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2220142aa5f94ffabc832c2942879492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f859742e71124966b3b1dafcc6243f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5e37996964240028b44a8ede93d19e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4fce34397f54b37903c0ef2440b2956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b0aeeb2d4a74c24b39dac57c399a020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea0e3bd63ef47e6a8550dabeea1caa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}