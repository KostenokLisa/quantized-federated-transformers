{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ji1iLhW2eLC"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PRpKL7j9PrB",
        "outputId": "c6111a46-ba87-4d33-ffd4-e2225c4f634c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=a5624c1c54deb7616a8fce206870c825677c37a65db27fa42dd095165bddc92e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWOj0qDS9Tit",
        "outputId": "ede17cf0-87e4-4423-a8f4-25a12f5395f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.2-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
            "\u001b[K     |████████████████████████████████| 120 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 39.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.9.1 tokenizers-0.12.1 transformers-4.21.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTnMHgBt-LE5",
        "outputId": "3763dac9-4471-41e5-cbe7-432241781c1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTQFEZAR9ULB",
        "outputId": "7f832cce-38b4-43f5-9a19-d7536fbf541b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch==1.12.0\n",
            "  Downloading torch-1.12.0-cp37-cp37m-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.12.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.12.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.12.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.13.0\n",
            "  Downloading torchtext-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.0) (1.21.6)\n",
            "Requirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.0) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.13.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0->torchtext==0.13.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.0) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.13.0) (2.10)\n",
            "Installing collected packages: torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "Successfully installed torchtext-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.12.0\n",
        "!pip install torchtext==0.13.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLyH5koG9XAT",
        "outputId": "d88f5d53-1ede-4855-a961-3cad21d58539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata==0.4.0\n",
            "  Downloading torchdata-0.4.0-cp37-cp37m-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.12.0 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.0) (1.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata==0.4.0) (2.23.0)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.12.0->torchdata==0.4.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0) (2022.6.15)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 51.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.4.0) (2.10)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.5.1 torchdata-0.4.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QX9Exbj89Y_n"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import wget \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import transformers as ppb\n",
        "import random\n",
        "import warnings\n",
        "import math\n",
        "import copy\n",
        "from packaging import version\n",
        "from torch import Tensor, nn\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlv7x0JY9bxf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oraovivw3hkC"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3lSQcdK3xrl"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import Multi30k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aysbyIM64C_T"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MarianConfig, PreTrainedModel\n",
        "from transformers.modeling_outputs import BaseModelOutput, BaseModelOutputWithPastAndCrossAttentions, Seq2SeqModelOutput, Seq2SeqLMOutput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI_mRLez4RNO",
        "outputId": "acf7afd9-eb88-4e0c-d765-33105f8483c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBvrZ5vi4RNP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/HBFPEmulator/bfp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04MMLDsi4RNP"
      },
      "outputs": [],
      "source": [
        "from bfp_ops import BFPLinear, BFPConv2d, unpack_bfp_args, _get_bfp_op, float_to_bfp_tiled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsK4nvJ2v0f6"
      },
      "outputs": [],
      "source": [
        "from bfp_optim import _gen_bfp_optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LLqw96O-AED"
      },
      "outputs": [],
      "source": [
        "from bfp_optim_lstm import BFPAdam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WnGdS_Wp4izs"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Optional, Tuple, Union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G-bJO4t8-eP"
      },
      "outputs": [],
      "source": [
        "from transformers.models.marian.modeling_marian import _expand_mask, _make_causal_mask, shift_tokens_right"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4_9YA1r9JKh"
      },
      "outputs": [],
      "source": [
        "from transformers.models.marian.modeling_marian import MarianSinusoidalPositionalEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZE_9UrEsr-M"
      },
      "outputs": [],
      "source": [
        "from transformers.activations import get_activation, ACT2FN, SiLUActivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElJ57Kbz8Dlj"
      },
      "source": [
        "## Activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZydXEjbODM2"
      },
      "source": [
        "## Baseline for MT + utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ-R5o4f-CDP",
        "outputId": "bb86cd5a-4286-41e1-e49e-28a5f92345f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 29001\n",
            "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n"
          ]
        }
      ],
      "source": [
        "train_iter = Multi30k(split=\"train\")\n",
        "\n",
        "# torchtext.datasets.DatasetName yield exhaustible IterableDataset.\n",
        "# To fix this we convert our dataset to a list.\n",
        "train_data = list(train_iter)\n",
        "\n",
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WWJdzues7Ek",
        "outputId": "da61dc80-3e2b-4f2d-8c3d-77e0ec6b3b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14500\n",
            "14500\n"
          ]
        }
      ],
      "source": [
        "train_data_1 = train_data[:14500]\n",
        "train_data_2 = train_data[14500:29000]\n",
        "print(len(train_data_1))\n",
        "print(len(train_data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSqxcjAI-F1w",
        "outputId": "6d2dabfa-5280-41fc-ab93-31beca27beee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of test examples: 1000\n",
            "('Ein Mann mit einem orangefarbenen Hut, der etwas anstarrt.', 'A man in an orange hat starring at something.')\n"
          ]
        }
      ],
      "source": [
        "test_iter = Multi30k(split=\"test\")\n",
        "test_data = list(test_iter)\n",
        "print(f\"Number of test examples: {len(test_data)}\")\n",
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiUGv7YpvNG3",
        "outputId": "e2a8770e-ed78-4204-cc89-20bc7d10a0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n",
            "500\n"
          ]
        }
      ],
      "source": [
        "test_data_1 = test_data[:500]\n",
        "test_data_2 = test_data[500:1000]\n",
        "print(len(test_data_1))\n",
        "print(len(test_data_2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "95a2ecfc0df14e07bb88195822180f1e",
            "55cfecb6d868450f825dd777c6a5e032",
            "3c46e3b7f2164b3f98ad8e4d903333f4",
            "372d3e10b4624cabb53c4b9f0cc871a1",
            "f4fd7e11fb5542e49d4b09e42bce50c5",
            "69e493b07815487d993e40495b4aa953",
            "b640b088f941453d9494428830535108",
            "f1412309994a40b698d2b7371dbc498e",
            "6eda739bf78247f4b4667864da08b239",
            "ff7cd47ae9f045d39a84d03b2605ced5",
            "d29bb1058e8d44c4a6b86cd2c175096b",
            "5270f0f6e781400fbbfff34a3cd22bf4",
            "58e42271d8fb4eaba771b60681f1eee4",
            "485902ad7f7a40d5acbbff77af093fc5",
            "910db3428a514d31be8e309615619bbd",
            "7cba82bedcf141ca97886e49597838b9",
            "855c3b46188244da87d7c837c385e453",
            "1a3626487ced42d692089d5e4e4bc689",
            "f7887c8cb9d2498cbcc81b7bc606a035",
            "43ffdd02b39341aab64eca07e493f90c",
            "4bfd878676ef4394a80b968e88a452ee",
            "99c4e4c9748e4b228105e7d4ac0dab95",
            "fe114834509f4b53b21f741b42ced760",
            "e7b2dd516bae41d598af21886c644818",
            "5cb0f2ee33264b389917b828426d5ca9",
            "1f49e63af2c5403daf5f07cba4a57a96",
            "c7ad9d8f5a7c42299bf1254da4976411",
            "4b9f4cc7e5d34d80893e883646cf7df9",
            "1612d3e4a0ff4b538dcf48c4acffcae9",
            "d67c46261d8a4d20b4d06b1dddba7b31",
            "338f2533021448b5b1af11088eab81ae",
            "051c7f44da0c49cea5143bb70c5cb0b6",
            "d1a026113729465986e7c20e2d503d71",
            "c7f6ba6a8d7b4e4b8d0b3c9ad0fa03ba",
            "5d6b9ee0b5544b769cd366e873ed6006",
            "a3559ec0193047ddb8059f9e77aa8ccf",
            "dc7ea4c6963b4c9f8df5c7f584ea2e50",
            "806e4cec94654450bdacc72b67b9d020",
            "e3c217e8a31c428288810e42695a32fe",
            "99fd0972dab248449331e230b0ff4353",
            "46054c74983a49e88144a2409de2c138",
            "db974521d21d42008eeeca003cdb2e94",
            "59420f225f67442283ea71e81069257f",
            "353f49cc24f9425ea9464203ef85b3b1",
            "6aeb67add48845da8aca416207f9e643",
            "079b541cd84a442084c178fe2cf4b95b",
            "759a8006daa64653a6f72822b9ddc6d7",
            "c8a4a5377ce04df39311f4299651c2ce",
            "75c666ab586a4c539d2211512aa8d650",
            "33c4c536236846f7b03bdc512f42aa5e",
            "929c37e79c2a47da815c8317eb8177f7",
            "aea7d2bc3a9c469e83ca423a788fcc89",
            "02077c33037d473e8b1a824426924453",
            "b485bd40efe9497dbd405cd74fa7e163",
            "df08cf48d7264a96872c6b71de965d4a",
            "1c0a180df5424046a6959119f2f9cc0e",
            "262903e0b7254d7d8c07a4b512f2fc4d",
            "14df44e474024c559f6a9fe8d784a1b8",
            "7c576605bda34166a7eb14070151e8e6",
            "68b078b37d6d4a96871f9f11e80d8c87",
            "1d09df3b7d344200bb93af88a3142c33",
            "0cd047fbd98a420ea34f292fe4149aae",
            "f7c8997a4efc4125803c06ae4672456d",
            "a476f8bdef374dc786459f1ec640dcf8",
            "004a41cfd22c418ca75ececfae791636",
            "429318062e504b76bfc0e6d5834a7b14"
          ]
        },
        "id": "YpWSsmZk-QTZ",
        "outputId": "354ca5ae-924c-448a-c85b-ac9d3894bd5d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95a2ecfc0df14e07bb88195822180f1e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5270f0f6e781400fbbfff34a3cd22bf4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe114834509f4b53b21f741b42ced760",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f6ba6a8d7b4e4b8d0b3c9ad0fa03ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading target.spm:   0%|          | 0.00/750k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6aeb67add48845da8aca416207f9e643",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading vocab.json:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c0a180df5424046a6959119f2f9cc0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/284M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'Helsinki-NLP/opus-mt-de-en'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "native_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGi59LsAWf2"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():     \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "native_model = native_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_UtgK98AZWG",
        "outputId": "7d7c29f9-3e06-4418-a98c-e7a021372ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MarianMTModel(\n",
              "  (model): MarianModel(\n",
              "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
              "    (encoder): MarianEncoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MarianEncoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): MarianDecoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): MarianDecoderLayer(\n",
              "          (self_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): MarianAttention(\n",
              "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=512, out_features=58101, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "native_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA1ElA833jrK"
      },
      "outputs": [],
      "source": [
        "def prepare_data(train_data, test_data):\n",
        "    src_train_raw = []\n",
        "    dst_train_raw = []\n",
        "    src_val_raw = []\n",
        "    dst_val_raw = []  \n",
        "    for line in train_data:\n",
        "        src_train_raw.append(line[1].lower())\n",
        "        dst_train_raw.append(line[0].lower()) \n",
        "    for line in test_data:\n",
        "        src_val_raw.append(line[1].lower())\n",
        "        dst_val_raw.append(line[0].lower())\n",
        "    src_train = tokenizer(src_train_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    dest_train = tokenizer(dst_train_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    src_val = tokenizer(src_val_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    dest_val = tokenizer(dst_val_raw, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    return src_train, dest_train, src_val, dest_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUG4pq2h475y"
      },
      "outputs": [],
      "source": [
        "src_train_1, dest_train_1, src_val_1, dest_val_1 = prepare_data(train_data_1, test_data_1)\n",
        "src_train_2, dest_train_2, src_val_2, dest_val_2 = prepare_data(train_data_2, test_data_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8rOiSUH8ZRd"
      },
      "outputs": [],
      "source": [
        "def estimate_bleu(model, inp_idx, out_idx, batch_size):\n",
        "    tokenizer_W = WordPunctTokenizer()\n",
        "    with torch.no_grad():\n",
        "        translations = []\n",
        "        inp_idx = inp_idx.to(device)\n",
        "        prev_i = 0\n",
        "        for i in tqdm.notebook.tqdm(range(batch_size, len(inp_idx) + batch_size, batch_size)):\n",
        "            output = model.generate(inp_idx[prev_i:i]).cpu()\n",
        "            prev_i = i\n",
        "            translations.extend(tokenizer.batch_decode(output, skip_special_tokens=True))\n",
        "        actual = tokenizer.batch_decode(out_idx, skip_special_tokens=True)\n",
        "        return corpus_bleu(\n",
        "            [[tokenizer_W.tokenize(ref)] for ref in actual],\n",
        "            [tokenizer_W.tokenize(trans.lower()) for trans in translations],\n",
        "            smoothing_function=lambda precisions, **kw: [p + 1.0 / p.denominator for p in precisions]\n",
        "            ) * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPFlNXCJhBix",
        "outputId": "58be56bd-83b4-457d-d190-3c60df231338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MarianConfig {\n",
            "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-de-en\",\n",
            "  \"_num_labels\": 3,\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"swish\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"MarianMTModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bad_words_ids\": [\n",
            "    [\n",
            "      58100\n",
            "    ]\n",
            "  ],\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classif_dropout\": 0.0,\n",
            "  \"classifier_dropout\": 0.0,\n",
            "  \"d_model\": 512,\n",
            "  \"decoder_attention_heads\": 8,\n",
            "  \"decoder_ffn_dim\": 2048,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 58100,\n",
            "  \"decoder_vocab_size\": 58101,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 8,\n",
            "  \"encoder_ffn_dim\": 2048,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 0,\n",
            "  \"forced_eos_token_id\": 0,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2\n",
            "  },\n",
            "  \"max_length\": 512,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"marian\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": false,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 58100,\n",
            "  \"scale_embedding\": true,\n",
            "  \"share_encoder_decoder_embeddings\": true,\n",
            "  \"static_position_embeddings\": true,\n",
            "  \"transformers_version\": \"4.21.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 58101\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(native_model.config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFZTnI1g8e7D"
      },
      "source": [
        "## Quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lCaeZe4JCig"
      },
      "outputs": [],
      "source": [
        "config = MarianConfig(activation_dropout=native_model.config.activation_dropout,\n",
        "activation_function=native_model.config.activation_function,\n",
        "attention_dropout=native_model.config.attention_dropout,\n",
        "classifier_dropout=native_model.config.classifier_dropout,\n",
        "d_model=native_model.config.d_model,\n",
        "decoder_attention_heads=native_model.config.decoder_attention_heads,\n",
        "decoder_ffn_dim=native_model.config.decoder_ffn_dim,\n",
        "decoder_layerdrop=native_model.config.decoder_layerdrop,\n",
        "decoder_layers=native_model.config.decoder_layers,\n",
        "decoder_start_token_id=native_model.config.decoder_start_token_id,\n",
        "decoder_vocab_size=native_model.config.decoder_vocab_size,\n",
        "dropout=native_model.config.dropout,\n",
        "encoder_attention_heads=native_model.config.encoder_attention_heads,\n",
        "encoder_ffn_dim=native_model.config.encoder_ffn_dim,\n",
        "encoder_layerdrop=native_model.config.encoder_layerdrop,\n",
        "encoder_layers=native_model.config.encoder_layers,\n",
        "eos_token_id=native_model.config.eos_token_id,\n",
        "forced_eos_token_id=native_model.config.forced_eos_token_id,\n",
        "init_std=native_model.config.init_std,\n",
        "is_encoder_decoder=native_model.config.is_encoder_decoder,\n",
        "max_position_embeddings=native_model.config.max_position_embeddings,\n",
        "model_type=native_model.config.model_type,\n",
        "num_hidden_layers=native_model.config.num_hidden_layers,\n",
        "pad_token_id=native_model.config.pad_token_id,\n",
        "scale_embedding=native_model.config.scale_embedding,\n",
        "share_encoder_decoder_embeddings=native_model.config.share_encoder_decoder_embeddings,\n",
        "transformers_version=native_model.config.transformers_version,\n",
        "use_cache=native_model.config.use_cache,\n",
        "vocab_size=native_model.config.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNkhA3U78pqh"
      },
      "outputs": [],
      "source": [
        "def BFPbmm(mat1, mat2, bfp_args={}):\n",
        "    if bfp_args[\"num_format\"] == \"bfp\":\n",
        "        op = _get_bfp_op(torch.bmm, \"bmm\", bfp_args)\n",
        "    else:\n",
        "        op = torch.bmm\n",
        "    return op(mat1, mat2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLia4Wat22rl"
      },
      "outputs": [],
      "source": [
        "class BFPMarianAttention(nn.Module):\n",
        "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embed_dim: int,\n",
        "        num_heads: int,\n",
        "        dropout: float = 0.0,\n",
        "        is_decoder: bool = False,\n",
        "        bias: bool = True,\n",
        "        bfp_args={}\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "        self.bfp_args = bfp_args\n",
        "\n",
        "        if (self.head_dim * num_heads) != self.embed_dim:\n",
        "            raise ValueError(\n",
        "                f\"embed_dim must be divisible by num_heads (got `embed_dim`: {self.embed_dim}\"\n",
        "                f\" and `num_heads`: {num_heads}).\"\n",
        "            )\n",
        "        self.scaling = self.head_dim**-0.5\n",
        "        self.is_decoder = is_decoder\n",
        "\n",
        "        self.k_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.v_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.q_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "        self.out_proj = BFPLinear(embed_dim, embed_dim, bias=bias, **bfp_args)\n",
        "\n",
        "\n",
        "    def _shape(self, tensor: torch.Tensor, seq_len: int, bsz: int):\n",
        "        return tensor.view(bsz, seq_len, self.num_heads, self.head_dim).transpose(1, 2).contiguous()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        key_value_states: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        output_attentions: bool = False\n",
        "    ) -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "        \"\"\"Input shape: Batch x Time x Channel\"\"\"\n",
        "\n",
        "        # if key_value_states are provided this layer is used as a cross-attention layer\n",
        "        # for the decoder\n",
        "        is_cross_attention = key_value_states is not None\n",
        "\n",
        "        bsz, tgt_len, _ = hidden_states.size()\n",
        "\n",
        "        # get query proj\n",
        "        query_states = self.q_proj(hidden_states) * self.scaling\n",
        "        # get key, value proj\n",
        "        if is_cross_attention and past_key_value is not None:\n",
        "            # reuse k,v, cross_attentions\n",
        "            key_states = past_key_value[0]\n",
        "            value_states = past_key_value[1]\n",
        "        elif is_cross_attention:\n",
        "            # cross_attentions\n",
        "            key_states = self._shape(self.k_proj(key_value_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(key_value_states), -1, bsz)\n",
        "        elif past_key_value is not None:\n",
        "            # reuse k, v, self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "            key_states = torch.cat([past_key_value[0], key_states], dim=2)\n",
        "            value_states = torch.cat([past_key_value[1], value_states], dim=2)\n",
        "        else:\n",
        "            # self_attention\n",
        "            key_states = self._shape(self.k_proj(hidden_states), -1, bsz)\n",
        "            value_states = self._shape(self.v_proj(hidden_states), -1, bsz)\n",
        "\n",
        "        if self.is_decoder:\n",
        "            past_key_value = (key_states, value_states)\n",
        "\n",
        "        proj_shape = (bsz * self.num_heads, -1, self.head_dim)\n",
        "        query_states = self._shape(query_states, tgt_len, bsz).view(*proj_shape)\n",
        "        key_states = key_states.view(*proj_shape)\n",
        "        value_states = value_states.view(*proj_shape)\n",
        "\n",
        "        src_len = key_states.size(1)\n",
        "        attn_weights = BFPbmm(query_states, key_states.transpose(1, 2), self.bfp_args)\n",
        "\n",
        "        if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
        "            raise ValueError(\n",
        "                f\"Attention weights should be of size {(bsz * self.num_heads, tgt_len, src_len)}, but is\"\n",
        "                f\" {attn_weights.size()}\"\n",
        "            )\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
        "                raise ValueError(\n",
        "                    f\"Attention mask should be of size {(bsz, 1, tgt_len, src_len)}, but is {attention_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = attn_weights.view(bsz, self.num_heads, tgt_len, src_len) + attention_mask\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        attn_weights = nn.functional.softmax(attn_weights, dim=-1)\n",
        "\n",
        "        if layer_head_mask is not None:\n",
        "            if layer_head_mask.size() != (self.num_heads,):\n",
        "                raise ValueError(\n",
        "                    f\"Head mask for a single layer should be of size {(self.num_heads,)}, but is\"\n",
        "                    f\" {layer_head_mask.size()}\"\n",
        "                )\n",
        "            attn_weights = layer_head_mask.view(1, -1, 1, 1) * attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "\n",
        "        if output_attentions:\n",
        "            attn_weights_reshaped = attn_weights.view(bsz, self.num_heads, tgt_len, src_len)\n",
        "            attn_weights = attn_weights_reshaped.view(bsz * self.num_heads, tgt_len, src_len)\n",
        "        else:\n",
        "            attn_weights_reshaped = None\n",
        "\n",
        "        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n",
        "        attn_output = BFPbmm(attn_probs, value_states, self.bfp_args)\n",
        "\n",
        "        if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
        "            raise ValueError(\n",
        "                f\"`attn_output` should be of size {(bsz, self.num_heads, tgt_len, self.head_dim)}, but is\"\n",
        "                f\" {attn_output.size()}\"\n",
        "            )\n",
        "\n",
        "        attn_output = attn_output.view(bsz, self.num_heads, tgt_len, self.head_dim)\n",
        "        attn_output = attn_output.transpose(1, 2)\n",
        "\n",
        "        attn_output = attn_output.reshape(bsz, tgt_len, self.embed_dim)\n",
        "\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "        return attn_output, attn_weights_reshaped, past_key_value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HE95byLX0x4v"
      },
      "outputs": [],
      "source": [
        "class BFPMarianEncoderLayer(nn.Module):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__()\n",
        "        # self.embed_dim = config.d_model\n",
        "        self.embed_dim = 512\n",
        "        self.self_attn = BFPMarianAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=8,\n",
        "            dropout=0.0,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.dropout = 0.1\n",
        "\n",
        "        self.activation_fn = ACT2FN[\"swish\"]\n",
        "        self.activation_dropout = 0.0\n",
        "        self.fc1 = BFPLinear(self.embed_dim, 2048, **bfp_args)\n",
        "        self.fc2 = BFPLinear(2048, self.embed_dim, **bfp_args)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.FloatTensor,\n",
        "        attention_mask: torch.FloatTensor,\n",
        "        layer_head_mask: torch.FloatTensor,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[torch.FloatTensor]]:\n",
        "      \n",
        "        residual = hidden_states\n",
        "        hidden_states, attn_weights, _ = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        if hidden_states.dtype == torch.float16 and (\n",
        "            torch.isinf(hidden_states).any() or torch.isnan(hidden_states).any()\n",
        "        ):\n",
        "            clamp_value = torch.finfo(hidden_states.dtype).max - 1000\n",
        "            hidden_states = torch.clamp(hidden_states, min=-clamp_value, max=clamp_value)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (attn_weights,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPq3y327czp-"
      },
      "outputs": [],
      "source": [
        "class BFPMarianPreTrainedModel(PreTrainedModel):\n",
        "    # config_class = MarianConfig\n",
        "    base_model_prefix = \"model\"\n",
        "    supports_gradient_checkpointing = True\n",
        "\n",
        "    def _init_weights(self, module: Union[nn.Linear, nn.Embedding, MarianSinusoidalPositionalEmbedding]):\n",
        "        std = 0.02\n",
        "        if isinstance(module, nn.Linear):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        elif isinstance(module, MarianSinusoidalPositionalEmbedding):\n",
        "            pass\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            module.weight.data.normal_(mean=0.0, std=std)\n",
        "            if module.padding_idx is not None:\n",
        "                module.weight.data[module.padding_idx].zero_()\n",
        "\n",
        "    def _set_gradient_checkpointing(self, module, value=False):\n",
        "        if isinstance(module, (BFPMarianDecoder, BFPMarianEncoder)):\n",
        "            module.gradient_checkpointing = value\n",
        "\n",
        "    @property\n",
        "    def dummy_inputs(self):\n",
        "        pad_token = 58100\n",
        "        input_ids = torch.tensor([[0, 6, 10, 4, 2], [0, 8, 12, 2, pad_token]], device=self.device)\n",
        "        dummy_inputs = {\n",
        "            \"attention_mask\": input_ids.ne(pad_token),\n",
        "            \"input_ids\": input_ids,\n",
        "            \"decoder_input_ids\": input_ids,\n",
        "        }\n",
        "        return dummy_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjtwQk3VO0xx"
      },
      "outputs": [],
      "source": [
        "class BFPMarianEncoder(BFPMarianPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer encoder consisting of *config.encoder_layers* self attention layers. Each layer is a\n",
        "    [`MarianEncoderLayer`].\n",
        "    Args:\n",
        "        config: MarianConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: MarianConfig, embed_tokens: Optional[nn.Embedding] = None, bfp_args={}):\n",
        "        super().__init__(config, bfp_args)\n",
        "\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.encoder_layerdrop\n",
        "\n",
        "        embed_dim = config.d_model\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_source_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(embed_dim) if config.scale_embedding else 1.0\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens = embed_tokens\n",
        "        else:\n",
        "            self.embed_tokens = nn.Embedding(config.vocab_size, embed_dim, self.padding_idx)\n",
        "\n",
        "        self.embed_positions = MarianSinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings, embed_dim, self.padding_idx\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BFPMarianEncoderLayer(config, bfp_args) for _ in range(config.encoder_layers)])\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutput]:\n",
        "   \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both input_ids and inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either input_ids or inputs_embeds\")\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
        "\n",
        "        embed_pos = self.embed_positions(input_shape)\n",
        "\n",
        "        hidden_states = inputs_embeds + embed_pos\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        # expand attention_mask\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            attention_mask = _expand_mask(attention_mask, inputs_embeds.dtype)\n",
        "\n",
        "        encoder_states = () if output_hidden_states else None\n",
        "        all_attentions = () if output_attentions else None\n",
        "\n",
        "        # check if head_mask has a correct number of layers specified if desired\n",
        "        if head_mask is not None:\n",
        "            assert head_mask.size()[0] == (\n",
        "                len(self.layers)\n",
        "            ), f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"\n",
        "        for idx, encoder_layer in enumerate(self.layers):\n",
        "            if output_hidden_states:\n",
        "                encoder_states = encoder_states + (hidden_states,)\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            dropout_probability = random.uniform(0, 1)\n",
        "            if self.training and (dropout_probability < self.layerdrop):  # skip the layer\n",
        "                layer_outputs = (None, None)\n",
        "            else:\n",
        "                if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                    def create_custom_forward(module):\n",
        "                        def custom_forward(*inputs):\n",
        "                            return module(*inputs, output_attentions)\n",
        "\n",
        "                        return custom_forward\n",
        "\n",
        "                    layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                        create_custom_forward(encoder_layer),\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        (head_mask[idx] if head_mask is not None else None),\n",
        "                    )\n",
        "                else:\n",
        "                    layer_outputs = encoder_layer(\n",
        "                        hidden_states,\n",
        "                        attention_mask,\n",
        "                        layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                        output_attentions=output_attentions,\n",
        "                    )\n",
        "\n",
        "                hidden_states = layer_outputs[0]\n",
        "\n",
        "            if output_attentions:\n",
        "                all_attentions = all_attentions + (layer_outputs[1],)\n",
        "\n",
        "        if output_hidden_states:\n",
        "            encoder_states = encoder_states + (hidden_states,)\n",
        "\n",
        "        if not return_dict:\n",
        "            return tuple(v for v in [hidden_states, encoder_states, all_attentions] if v is not None)\n",
        "        return BaseModelOutput(\n",
        "            last_hidden_state=hidden_states, hidden_states=encoder_states, attentions=all_attentions\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIgrNG8K7XN3"
      },
      "outputs": [],
      "source": [
        "class BFPMarianDecoderLayer(nn.Module):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__()\n",
        "        self.embed_dim = config.d_model\n",
        "\n",
        "        self.self_attn = BFPMarianAttention(\n",
        "            embed_dim=self.embed_dim,\n",
        "            num_heads=config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.dropout = config.dropout\n",
        "        self.activation_fn = ACT2FN[\"swish\"]\n",
        "        self.activation_dropout = config.activation_dropout\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.encoder_attn = BFPMarianAttention(\n",
        "            self.embed_dim,\n",
        "            config.decoder_attention_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            is_decoder=True,\n",
        "            bfp_args=bfp_args\n",
        "        )\n",
        "        self.encoder_attn_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "        self.fc1 = BFPLinear(self.embed_dim, config.decoder_ffn_dim, **bfp_args)\n",
        "        self.fc2 = BFPLinear(config.decoder_ffn_dim, self.embed_dim, **bfp_args)\n",
        "        self.final_layer_norm = nn.LayerNorm(self.embed_dim)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        hidden_states: torch.Tensor,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_layer_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
        "        output_attentions: Optional[bool] = False,\n",
        "        use_cache: Optional[bool] = True,\n",
        "    ) -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
        "      \n",
        "        residual = hidden_states\n",
        "\n",
        "        # Self Attention\n",
        "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
        "        self_attn_past_key_value = past_key_value[:2] if past_key_value is not None else None\n",
        "        # add present self-attn cache to positions 1,2 of present_key_value tuple\n",
        "        hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
        "            hidden_states=hidden_states,\n",
        "            past_key_value=self_attn_past_key_value,\n",
        "            attention_mask=attention_mask,\n",
        "            layer_head_mask=layer_head_mask,\n",
        "            output_attentions=output_attentions,\n",
        "        )\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.self_attn_layer_norm(hidden_states)\n",
        "\n",
        "        # Cross-Attention Block\n",
        "        cross_attn_present_key_value = None\n",
        "        cross_attn_weights = None\n",
        "        if encoder_hidden_states is not None:\n",
        "            residual = hidden_states\n",
        "\n",
        "            # cross_attn cached key/values tuple is at positions 3,4 of present_key_value tuple\n",
        "            cross_attn_past_key_value = past_key_value[-2:] if past_key_value is not None else None\n",
        "            hidden_states, cross_attn_weights, cross_attn_present_key_value = self.encoder_attn(\n",
        "                hidden_states=hidden_states,\n",
        "                key_value_states=encoder_hidden_states,\n",
        "                attention_mask=encoder_attention_mask,\n",
        "                layer_head_mask=cross_attn_layer_head_mask,\n",
        "                past_key_value=cross_attn_past_key_value,\n",
        "                output_attentions=output_attentions,\n",
        "            )\n",
        "            hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "            hidden_states = residual + hidden_states\n",
        "            hidden_states = self.encoder_attn_layer_norm(hidden_states)\n",
        "\n",
        "            # add cross-attn to positions 3,4 of present_key_value tuple\n",
        "            present_key_value = present_key_value + cross_attn_present_key_value\n",
        "\n",
        "        # Fully Connected\n",
        "        residual = hidden_states\n",
        "        hidden_states = self.activation_fn(self.fc1(hidden_states))\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.activation_dropout, training=self.training)\n",
        "        hidden_states = self.fc2(hidden_states)\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "        hidden_states = residual + hidden_states\n",
        "        hidden_states = self.final_layer_norm(hidden_states)\n",
        "\n",
        "        outputs = (hidden_states,)\n",
        "\n",
        "        if output_attentions:\n",
        "            outputs += (self_attn_weights, cross_attn_weights)\n",
        "\n",
        "        if use_cache:\n",
        "            outputs += (present_key_value,)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JiyfjCVoIEa"
      },
      "outputs": [],
      "source": [
        "class BFPMarianDecoder(BFPMarianPreTrainedModel):\n",
        "    \"\"\"\n",
        "    Transformer decoder consisting of *config.decoder_layers* layers. Each layer is a [`MarianDecoderLayer`]\n",
        "    Args:\n",
        "        config: MarianConfig\n",
        "        embed_tokens (nn.Embedding): output embedding\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: MarianConfig, embed_tokens: Optional[nn.Embedding] = None, bfp_args={}):\n",
        "        super().__init__(config, bfp_args)\n",
        "        self.dropout = config.dropout\n",
        "        self.layerdrop = config.decoder_layerdrop\n",
        "        self.padding_idx = config.pad_token_id\n",
        "        self.max_target_positions = config.max_position_embeddings\n",
        "        self.embed_scale = math.sqrt(config.d_model) if config.scale_embedding else 1.0\n",
        "\n",
        "        if embed_tokens is not None:\n",
        "            self.embed_tokens = embed_tokens\n",
        "        else:\n",
        "            self.embed_tokens = nn.Embedding(config.decoder_vocab_size, config.d_model, self.padding_idx)\n",
        "\n",
        "        self.embed_positions = MarianSinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings, config.d_model, self.padding_idx\n",
        "        )\n",
        "        self.layers = nn.ModuleList([BFPMarianDecoderLayer(config, bfp_args) for _ in range(config.decoder_layers)])\n",
        "\n",
        "        self.gradient_checkpointing = False\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        return self.embed_tokens\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        self.embed_tokens = value\n",
        "\n",
        "    # Copied from transformers.models.bart.modeling_bart.BartDecoder._prepare_decoder_attention_mask\n",
        "    def _prepare_decoder_attention_mask(self, attention_mask, input_shape, inputs_embeds, past_key_values_length):\n",
        "        # create causal mask\n",
        "        # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "        combined_attention_mask = None\n",
        "        if input_shape[-1] > 1:\n",
        "            combined_attention_mask = _make_causal_mask(\n",
        "                input_shape, inputs_embeds.dtype, past_key_values_length=past_key_values_length\n",
        "            ).to(inputs_embeds.device)\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            expanded_attn_mask = _expand_mask(attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n",
        "            combined_attention_mask = (\n",
        "                expanded_attn_mask if combined_attention_mask is None else expanded_attn_mask + combined_attention_mask\n",
        "            )\n",
        "\n",
        "        return combined_attention_mask\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "        encoder_attention_mask: Optional[torch.LongTensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
        "       \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        # retrieve input_ids and inputs_embeds\n",
        "        if input_ids is not None and inputs_embeds is not None:\n",
        "            raise ValueError(\"You cannot specify both decoder_input_ids and decoder_inputs_embeds at the same time\")\n",
        "        elif input_ids is not None:\n",
        "            input_shape = input_ids.size()\n",
        "            input_ids = input_ids.view(-1, input_shape[-1])\n",
        "        elif inputs_embeds is not None:\n",
        "            input_shape = inputs_embeds.size()[:-1]\n",
        "        else:\n",
        "            raise ValueError(\"You have to specify either decoder_input_ids or decoder_inputs_embeds\")\n",
        "\n",
        "        # past_key_values_length\n",
        "        past_key_values_length = past_key_values[0][0].shape[2] if past_key_values is not None else 0\n",
        "\n",
        "        if inputs_embeds is None:\n",
        "            inputs_embeds = self.embed_tokens(input_ids) * self.embed_scale\n",
        "\n",
        "        attention_mask = self._prepare_decoder_attention_mask(\n",
        "            attention_mask, input_shape, inputs_embeds, past_key_values_length\n",
        "        )\n",
        "\n",
        "        # expand encoder attention mask\n",
        "        if encoder_hidden_states is not None and encoder_attention_mask is not None:\n",
        "            # [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]\n",
        "            encoder_attention_mask = _expand_mask(encoder_attention_mask, inputs_embeds.dtype, tgt_len=input_shape[-1])\n",
        "\n",
        "        # embed positions\n",
        "        positions = self.embed_positions(input_shape, past_key_values_length)\n",
        "\n",
        "        hidden_states = inputs_embeds + positions\n",
        "\n",
        "        hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n",
        "\n",
        "        # decoder layers\n",
        "        all_hidden_states = () if output_hidden_states else None\n",
        "        all_self_attns = () if output_attentions else None\n",
        "        all_cross_attentions = () if (output_attentions and encoder_hidden_states is not None) else None\n",
        "        next_decoder_cache = () if use_cache else None\n",
        "\n",
        "        # check if head_mask/cross_attn_head_mask has a correct number of layers specified if desired\n",
        "        for attn_mask, mask_name in zip([head_mask, cross_attn_head_mask], [\"head_mask\", \"cross_attn_head_mask\"]):\n",
        "            if attn_mask is not None:\n",
        "                assert attn_mask.size()[0] == (len(self.layers)), (\n",
        "                    f\"The `{mask_name}` should be specified for {len(self.layers)} layers, but it is for\"\n",
        "                    f\" {head_mask.size()[0]}.\"\n",
        "                )\n",
        "        for idx, decoder_layer in enumerate(self.layers):\n",
        "            # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n",
        "            if output_hidden_states:\n",
        "                all_hidden_states += (hidden_states,)\n",
        "            dropout_probability = random.uniform(0, 1)\n",
        "            if self.training and (dropout_probability < self.layerdrop):\n",
        "                continue\n",
        "\n",
        "            past_key_value = past_key_values[idx] if past_key_values is not None else None\n",
        "\n",
        "            if self.gradient_checkpointing and self.training:\n",
        "\n",
        "                if use_cache:\n",
        "                    # logger.warning(\n",
        "                        # \"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"\n",
        "                    # )\n",
        "                    use_cache = False\n",
        "\n",
        "                def create_custom_forward(module):\n",
        "                    def custom_forward(*inputs):\n",
        "                        # None for past_key_value\n",
        "                        return module(*inputs, output_attentions, use_cache)\n",
        "\n",
        "                    return custom_forward\n",
        "\n",
        "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
        "                    create_custom_forward(decoder_layer),\n",
        "                    hidden_states,\n",
        "                    attention_mask,\n",
        "                    encoder_hidden_states,\n",
        "                    encoder_attention_mask,\n",
        "                    head_mask[idx] if head_mask is not None else None,\n",
        "                    cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None,\n",
        "                    None,\n",
        "                )\n",
        "            else:\n",
        "\n",
        "                layer_outputs = decoder_layer(\n",
        "                    hidden_states,\n",
        "                    attention_mask=attention_mask,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    encoder_attention_mask=encoder_attention_mask,\n",
        "                    layer_head_mask=(head_mask[idx] if head_mask is not None else None),\n",
        "                    cross_attn_layer_head_mask=(\n",
        "                        cross_attn_head_mask[idx] if cross_attn_head_mask is not None else None\n",
        "                    ),\n",
        "                    past_key_value=past_key_value,\n",
        "                    output_attentions=output_attentions,\n",
        "                    use_cache=use_cache,\n",
        "                )\n",
        "            hidden_states = layer_outputs[0]\n",
        "\n",
        "            if use_cache:\n",
        "                next_decoder_cache += (layer_outputs[3 if output_attentions else 1],)\n",
        "\n",
        "            if output_attentions:\n",
        "                all_self_attns += (layer_outputs[1],)\n",
        "\n",
        "                if encoder_hidden_states is not None:\n",
        "                    all_cross_attentions += (layer_outputs[2],)\n",
        "\n",
        "        # add hidden states from the last decoder layer\n",
        "        if output_hidden_states:\n",
        "            all_hidden_states += (hidden_states,)\n",
        "\n",
        "        next_cache = next_decoder_cache if use_cache else None\n",
        "        if not return_dict:\n",
        "            return tuple(\n",
        "                v\n",
        "                for v in [hidden_states, next_cache, all_hidden_states, all_self_attns, all_cross_attentions]\n",
        "                if v is not None\n",
        "            )\n",
        "        return BaseModelOutputWithPastAndCrossAttentions(\n",
        "            last_hidden_state=hidden_states,\n",
        "            past_key_values=next_cache,\n",
        "            hidden_states=all_hidden_states,\n",
        "            attentions=all_self_attns,\n",
        "            cross_attentions=all_cross_attentions,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNadqpYZapSt"
      },
      "outputs": [],
      "source": [
        "class BFPMarianModel(BFPMarianPreTrainedModel):\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__(config)\n",
        "\n",
        "        padding_idx, vocab_size = config.pad_token_id, config.vocab_size\n",
        "\n",
        "        # We always use self.shared for token embeddings to ensure compatibility with all marian models\n",
        "        self.shared = nn.Embedding(vocab_size, config.d_model, padding_idx)\n",
        "        encoder_embed_tokens = decoder_embed_tokens = self.shared\n",
        "\n",
        "        self.encoder = BFPMarianEncoder(config, encoder_embed_tokens, bfp_args)\n",
        "        self.decoder = BFPMarianDecoder(config, decoder_embed_tokens, bfp_args)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_input_embeddings(self):\n",
        "        # This will return shared embeddings if they are shared else specific to encoder.\n",
        "        return self.get_encoder().get_input_embeddings()\n",
        "\n",
        "    def set_input_embeddings(self, value):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self.shared = value\n",
        "            self.encoder.embed_tokens = self.shared\n",
        "            self.decoder.embed_tokens = self.shared\n",
        "        else:  # if not shared only set encoder embeedings\n",
        "            self.encoder.embed_tokens = value\n",
        "\n",
        "    def get_decoder_input_embeddings(self):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`get_decoder_input_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `get_input_embeddings` instead.\"\n",
        "            )\n",
        "        return self.get_decoder().get_input_embeddings()\n",
        "\n",
        "    def set_decoder_input_embeddings(self, value):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`config.share_encoder_decoder_embeddings` is set to `True` meaning the decoder input embeddings \"\n",
        "                \"are shared with the encoder. In order to set the decoder input embeddings, you should simply set \"\n",
        "                \"the encoder input embeddings by calling `set_input_embeddings` with the appropriate embeddings.\"\n",
        "            )\n",
        "        self.decoder.embed_tokens = value\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.decoder\n",
        "\n",
        "    def resize_decoder_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`resize_decoder_token_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `resize_token_embeddings` instead.\"\n",
        "            )\n",
        "\n",
        "        old_embeddings = self.get_decoder_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.set_decoder_input_embeddings(new_embeddings)\n",
        "\n",
        "        model_embeds = self.get_decoder_input_embeddings()\n",
        "\n",
        "        if new_num_tokens is None:\n",
        "            return model_embeds\n",
        "\n",
        "        # Update base model and current model config\n",
        "        self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # Tie weights again if needed\n",
        "        self.tie_weights()\n",
        "\n",
        "        return model_embeds\n",
        "\n",
        "    # @add_start_docstrings_to_model_forward(MARIAN_INPUTS_DOCSTRING)\n",
        "    # @replace_return_docstrings(output_type=Seq2SeqModelOutput, config_class=_CONFIG_FOR_DOC)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Seq2SeqModelOutput:\n",
        "        \n",
        "        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n",
        "        output_hidden_states = (\n",
        "            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n",
        "        )\n",
        "        use_cache = use_cache if use_cache is not None else self.config.use_cache\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if encoder_outputs is None:\n",
        "            encoder_outputs = self.encoder(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                head_mask=head_mask,\n",
        "                inputs_embeds=inputs_embeds,\n",
        "                output_attentions=output_attentions,\n",
        "                output_hidden_states=output_hidden_states,\n",
        "                return_dict=return_dict,\n",
        "            )\n",
        "        # If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\n",
        "        elif return_dict and not isinstance(encoder_outputs, BaseModelOutput):\n",
        "            encoder_outputs = BaseModelOutput(\n",
        "                last_hidden_state=encoder_outputs[0],\n",
        "                hidden_states=encoder_outputs[1] if len(encoder_outputs) > 1 else None,\n",
        "                attentions=encoder_outputs[2] if len(encoder_outputs) > 2 else None,\n",
        "            )\n",
        "\n",
        "        # decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            encoder_hidden_states=encoder_outputs[0],\n",
        "            encoder_attention_mask=attention_mask,\n",
        "            head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        if not return_dict:\n",
        "            return decoder_outputs + encoder_outputs\n",
        "\n",
        "        return Seq2SeqModelOutput(\n",
        "            last_hidden_state=decoder_outputs.last_hidden_state,\n",
        "            past_key_values=decoder_outputs.past_key_values,\n",
        "            decoder_hidden_states=decoder_outputs.hidden_states,\n",
        "            decoder_attentions=decoder_outputs.attentions,\n",
        "            cross_attentions=decoder_outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=encoder_outputs.last_hidden_state,\n",
        "            encoder_hidden_states=encoder_outputs.hidden_states,\n",
        "            encoder_attentions=encoder_outputs.attentions,\n",
        "        )\n",
        "\n",
        "\n",
        "      # @add_start_docstrings(\n",
        "   # \"The Marian Model with a language modeling head. Can be used for summarization.\", MARIAN_START_DOCSTRING\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaqZqURA972w"
      },
      "outputs": [],
      "source": [
        "class BFPMarianMTModel(BFPMarianPreTrainedModel):\n",
        "    base_model_prefix = \"model\"\n",
        "    _keys_to_ignore_on_load_missing = [\n",
        "        r\"final_logits_bias\",\n",
        "        r\"encoder.version\",\n",
        "        r\"decoder.version\",\n",
        "        r\"lm_head.weight\",\n",
        "        r\"embed_positions\",\n",
        "    ]\n",
        "\n",
        "    _keys_to_ignore_on_save = [\"model.encoder.embed_positions.weight\", \"model.decoder.embed_positions.weight\"]\n",
        "\n",
        "    def __init__(self, config: MarianConfig, bfp_args={}):\n",
        "        super().__init__(config)\n",
        "        self.model = BFPMarianModel(config, bfp_args)\n",
        "\n",
        "        target_vocab_size = config.vocab_size if config.share_encoder_decoder_embeddings else config.decoder_vocab_size\n",
        "        self.register_buffer(\"final_logits_bias\", torch.zeros((1, target_vocab_size)))\n",
        "        self.lm_head = BFPLinear(512, target_vocab_size, bias=False, bfp_args = bfp_args)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.model.get_encoder()\n",
        "\n",
        "    def get_decoder(self):\n",
        "        return self.model.get_decoder()\n",
        "\n",
        "    def resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        new_embeddings = super().resize_token_embeddings(new_num_tokens)\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self._resize_final_logits_bias(new_num_tokens)\n",
        "        return new_embeddings\n",
        "\n",
        "    def _resize_token_embeddings(self, new_num_tokens: int) -> nn.Embedding:\n",
        "        old_embeddings = self.get_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.set_input_embeddings(new_embeddings)\n",
        "\n",
        "        # update config.decoder_vocab_size if embeddings are tied\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # if word embeddings are not tied, make sure that lm head is resized as well\n",
        "        if (\n",
        "            self.config.share_encoder_decoder_embeddings\n",
        "            and self.get_output_embeddings() is not None\n",
        "            and not self.config.tie_word_embeddings\n",
        "        ):\n",
        "            old_lm_head = self.get_output_embeddings()\n",
        "            new_lm_head = self._get_resized_lm_head(old_lm_head, new_num_tokens)\n",
        "            self.set_output_embeddings(new_lm_head)\n",
        "\n",
        "        return self.get_input_embeddings()\n",
        "\n",
        "    def resize_decoder_token_embeddings(self, new_num_tokens):\n",
        "        if self.config.share_encoder_decoder_embeddings:\n",
        "            raise ValueError(\n",
        "                \"`resize_decoder_token_embeddings` should not be called if `config.share_encoder_decoder_embeddings` \"\n",
        "                \"is `True`. Please use `resize_token_embeddings` instead.\"\n",
        "            )\n",
        "\n",
        "        old_embeddings = self.model.get_decoder_input_embeddings()\n",
        "        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens)\n",
        "        self.model.set_decoder_input_embeddings(new_embeddings)\n",
        "\n",
        "        # if word embeddings are not tied, make sure that lm head is resized as well\n",
        "        if self.get_output_embeddings() is not None and not self.config.tie_word_embeddings:\n",
        "            old_lm_head = self.get_output_embeddings()\n",
        "            new_lm_head = self._get_resized_lm_head(old_lm_head, new_num_tokens)\n",
        "            self.set_output_embeddings(new_lm_head)\n",
        "\n",
        "        model_embeds = self.model.get_decoder_input_embeddings()\n",
        "\n",
        "        if new_num_tokens is None:\n",
        "            return model_embeds\n",
        "\n",
        "        # Update base model and current model config\n",
        "        self.config.decoder_vocab_size = new_num_tokens\n",
        "\n",
        "        # Tie weights again if needed\n",
        "        self.tie_weights()\n",
        "\n",
        "        self._resize_final_logits_bias(new_num_tokens)\n",
        "\n",
        "        return model_embeds\n",
        "\n",
        "    def _resize_final_logits_bias(self, new_num_tokens: int) -> None:\n",
        "        old_num_tokens = self.final_logits_bias.shape[-1]\n",
        "        if new_num_tokens <= old_num_tokens:\n",
        "            new_bias = self.final_logits_bias[:, :new_num_tokens]\n",
        "        else:\n",
        "            extra_bias = torch.zeros((1, new_num_tokens - old_num_tokens), device=self.final_logits_bias.device)\n",
        "            new_bias = torch.cat([self.final_logits_bias, extra_bias], dim=1)\n",
        "        self.register_buffer(\"final_logits_bias\", new_bias)\n",
        "\n",
        "    def get_output_embeddings(self):\n",
        "        return self.lm_head\n",
        "\n",
        "    def set_output_embeddings(self, new_embeddings: nn.Embedding):\n",
        "        self.lm_head = new_embeddings\n",
        "\n",
        "    def tie_weights(self):\n",
        "        \"\"\"\n",
        "        Tie the weights between the input embeddings and the output embeddings.\n",
        "        If the `torchscript` flag is set in the configuration, can't handle parameter sharing so we are cloning the\n",
        "        weights instead.\n",
        "        \"\"\"\n",
        "        output_embeddings = self.get_output_embeddings()\n",
        "        if output_embeddings is not None and getattr(self.config, \"tie_word_embeddings\", True):\n",
        "            # if embeddings are shared this will return shared embeddings otherwise decoder embed_tokens\n",
        "            word_embeddings = self.get_decoder().get_input_embeddings()\n",
        "            self._tie_or_clone_weights(output_embeddings, word_embeddings)\n",
        "\n",
        "        if getattr(self.config, \"is_encoder_decoder\", False) and getattr(self.config, \"tie_encoder_decoder\", False):\n",
        "            if hasattr(self, self.base_model_prefix):\n",
        "                self = getattr(self, self.base_model_prefix)\n",
        "            self._tie_encoder_decoder_weights(self.encoder, self.decoder, self.base_model_prefix)\n",
        "\n",
        "        for module in self.modules():\n",
        "            if hasattr(module, \"_tie_weights\"):\n",
        "                module._tie_weights()\n",
        "\n",
        "    # @add_start_docstrings_to_model_forward(MARIAN_INPUTS_DOCSTRING)\n",
        "    # @replace_return_docstrings(output_type=Seq2SeqLMOutput, config_class=_CONFIG_FOR_DOC)\n",
        "    # @add_end_docstrings(MARIAN_GENERATION_EXAMPLE)\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: torch.LongTensor = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_input_ids: Optional[torch.LongTensor] = None,\n",
        "        decoder_attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        past_key_values: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        decoder_inputs_embeds: Optional[torch.FloatTensor] = None,\n",
        "        labels: Optional[torch.LongTensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Seq2SeqLMOutput:\n",
        "       \n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        if labels is not None:\n",
        "            use_cache = False\n",
        "            if decoder_input_ids is None:\n",
        "                decoder_input_ids = shift_tokens_right(\n",
        "                    labels, self.config.pad_token_id, self.config.decoder_start_token_id\n",
        "                )\n",
        "\n",
        "        outputs = self.model(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            decoder_input_ids=decoder_input_ids,\n",
        "            encoder_outputs=encoder_outputs,\n",
        "            decoder_attention_mask=decoder_attention_mask,\n",
        "            head_mask=head_mask,\n",
        "            decoder_head_mask=decoder_head_mask,\n",
        "            cross_attn_head_mask=cross_attn_head_mask,\n",
        "            past_key_values=past_key_values,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            decoder_inputs_embeds=decoder_inputs_embeds,\n",
        "            use_cache=use_cache,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "        lm_logits = self.lm_head(outputs[0]) + self.final_logits_bias\n",
        "\n",
        "        masked_lm_loss = None\n",
        "        if labels is not None:\n",
        "            loss_fct = CrossEntropyLoss()\n",
        "            masked_lm_loss = loss_fct(lm_logits.view(-1, 58101), labels.view(-1))\n",
        "\n",
        "        if not return_dict:\n",
        "            output = (lm_logits,) + outputs[1:]\n",
        "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
        "\n",
        "        return Seq2SeqLMOutput(\n",
        "            loss=masked_lm_loss,\n",
        "            logits=lm_logits,\n",
        "            past_key_values=outputs.past_key_values,\n",
        "            decoder_hidden_states=outputs.decoder_hidden_states,\n",
        "            decoder_attentions=outputs.decoder_attentions,\n",
        "            cross_attentions=outputs.cross_attentions,\n",
        "            encoder_last_hidden_state=outputs.encoder_last_hidden_state,\n",
        "            encoder_hidden_states=outputs.encoder_hidden_states,\n",
        "            encoder_attentions=outputs.encoder_attentions,\n",
        "        )\n",
        "\n",
        "    def prepare_inputs_for_generation(\n",
        "        self,\n",
        "        decoder_input_ids: torch.LongTensor,\n",
        "        past: Optional[Tuple[Tuple[torch.FloatTensor]]] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        decoder_head_mask: Optional[torch.Tensor] = None,\n",
        "        cross_attn_head_mask: Optional[torch.Tensor] = None,\n",
        "        use_cache: Optional[bool] = None,\n",
        "        encoder_outputs: Optional[Union[Tuple[torch.Tensor], BaseModelOutput]] = None,\n",
        "        **kwargs,\n",
        "    ) -> Dict:\n",
        "        # cut decoder_input_ids if past is used\n",
        "        if past is not None:\n",
        "            decoder_input_ids = decoder_input_ids[:, -1:]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": None,  # encoder_outputs is defined. input_ids not needed\n",
        "            \"encoder_outputs\": encoder_outputs,\n",
        "            \"past_key_values\": past,\n",
        "            \"decoder_input_ids\": decoder_input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"head_mask\": head_mask,\n",
        "            \"decoder_head_mask\": decoder_head_mask,\n",
        "            \"cross_attn_head_mask\": cross_attn_head_mask,\n",
        "            \"use_cache\": use_cache,  # change this to avoid caching (presumably for debugging)\n",
        "        }\n",
        "\n",
        "    def prepare_decoder_input_ids_from_labels(self, labels: torch.Tensor):\n",
        "        return shift_tokens_right(labels, self.config.pad_token_id, self.config.decoder_start_token_id)\n",
        "\n",
        "    def adjust_logits_during_generation(self, logits, cur_len):\n",
        "        logits[:, self.config.pad_token_id] = float(\"-inf\")  # never predict pad token.\n",
        "        return logits\n",
        "\n",
        "    @staticmethod\n",
        "    def _reorder_cache(past, beam_idx):\n",
        "        reordered_past = ()\n",
        "        for layer_past in past:\n",
        "            # cached cross_attention states don't have to be reordered -> they are always the same\n",
        "            reordered_past += (\n",
        "                tuple(past_state.index_select(0, beam_idx) for past_state in layer_past[:2]) + layer_past[2:],\n",
        "            )\n",
        "        return reordered_past\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1dVNe7zB0Ma"
      },
      "outputs": [],
      "source": [
        "# bfp quantization arguments\n",
        "args = {\"num_format\": \"bfp\", \"rounding_mode\": \"stoc\", \"mant_bits\": 8, \n",
        "       \"bfp_tile_size\": 0, \"weight_mant_bits\": 16, \"device\": \"gpu\", \"epsilon\": 1e-8}\n",
        "model_1 = BFPMarianMTModel(config, args)\n",
        "model_2 = BFPMarianMTModel(config, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ftEFzCfI6hZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgBYE594Erg2"
      },
      "source": [
        "## Quantized model vs basic model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_yMPVrKzRNd"
      },
      "source": [
        "Load pretrained MarianMT model from transformers and estimate its score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqQdA7W1z7ro"
      },
      "outputs": [],
      "source": [
        "train_ids_1 = dest_train_1[\"input_ids\"]\n",
        "train_labels_1 = src_train_1[\"input_ids\"]\n",
        "train_mask_1 = dest_train_1[\"attention_mask\"] \n",
        "val_ids_1 = dest_val_1[\"input_ids\"]\n",
        "val_labels_1 = src_val_1[\"input_ids\"]\n",
        "val_mask_1 = dest_val_1[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PVhNPbK6j3K"
      },
      "outputs": [],
      "source": [
        "train_ids_2 = dest_train_2[\"input_ids\"]\n",
        "train_labels_2 = src_train_2[\"input_ids\"]\n",
        "train_mask_2 = dest_train_2[\"attention_mask\"] \n",
        "val_ids_2 = dest_val_2[\"input_ids\"]\n",
        "val_labels_2 = src_val_2[\"input_ids\"]\n",
        "val_mask_2 = dest_val_2[\"attention_mask\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6dfeab4b232d4b90acb13053ae1d64d0",
            "5869d43074c9413f8afbeb9200072c7e",
            "d67dcc7a11df4faf80c78cd509715377",
            "b3bedfbab80d44f7b58f3cf41428a4f9",
            "7a1500ff457646b4a773e94c9b29a48a",
            "6653e93147fd45e8ba50f51fffc35829",
            "76d5984519194db69c6f27139ef06ad0",
            "0115d389c3b945cbabf8791625fc935b",
            "818cf962d7bd4cf994aaa803f10a7b5f",
            "8896faaae6414f22a039b274d9735014",
            "8962b405e6644892b35863b3928077b0"
          ]
        },
        "id": "i5fOOfyLD0XC",
        "outputId": "1bef7143-762b-4e3e-ba13-c9c9d4db4264"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dfeab4b232d4b90acb13053ae1d64d0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "35.26688112022937"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimate_bleu(native_model, val_ids_1, val_labels_1, 16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42lj7zaO0bF6"
      },
      "outputs": [],
      "source": [
        "torch.save(native_model.state_dict(), \"init.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyDmE9j0JG5E",
        "outputId": "60556a7d-3a2e-458e-e7df-085452426bbd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BFPMarianMTModel(\n",
              "  (model): BFPMarianModel(\n",
              "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
              "    (encoder): BFPMarianEncoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): BFPMarianDecoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): BFPLinear(in_features=512, out_features=58101, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1.load_state_dict(torch.load(\"init.pth\"))\n",
        "model_1.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-e7pBz61uat"
      },
      "outputs": [],
      "source": [
        "model_1 = model_1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "3742dfb846f74d639405a2d53c3c4949",
            "f56deb7d6bd34becb83a7d30d5a173a8",
            "ffa85f4bad2c48c58c8d60c4be519c54",
            "41bd42171fc34b03a4170cc4610f8f28",
            "8fbc76dd78fa4bfb845f12bf0a104b97",
            "eba5e9bfb18440f3bcfe245c12d0cd0a",
            "b48daac1c862478d9de878fecd1a01d4",
            "c5353d0cb3dd461aa18f1511ad7b17ed",
            "4a673f4ca02d4474aca244abe3759b6c",
            "fe9648e0a2654c9d8cedda093d63529e",
            "3f7ecb9dec8744218bf7c824ea05540a"
          ]
        },
        "id": "dufp9cA5AsFQ",
        "outputId": "2a253097-df6d-42c3-8476-146f7c629355"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3742dfb846f74d639405a2d53c3c4949",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "34.146585485419735"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ids_1 = train_ids_1.to(device)\n",
        "train_labels_1 = train_labels_1.to(device)\n",
        "train_mask_1 = train_mask_1.to(device)\n",
        "val_ids_1 = val_ids_1.to(device)\n",
        "val_labels_1 = val_labels_1.to(device)\n",
        "val_mask_1 = val_mask_1.to(device)\n",
        "estimate_bleu(model_1, val_ids_1, val_labels_1, 16) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB8B-ZWJ9RQI",
        "outputId": "82921c38-271f-442c-f87b-21af762f80a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BFPMarianMTModel(\n",
              "  (model): BFPMarianModel(\n",
              "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
              "    (encoder): BFPMarianEncoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianEncoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (decoder): BFPMarianDecoder(\n",
              "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
              "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
              "      (layers): ModuleList(\n",
              "        (0): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (1): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (2): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (3): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (4): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "        (5): BFPMarianDecoderLayer(\n",
              "          (self_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (activation_fn): SiLUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BFPMarianAttention(\n",
              "            (k_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (v_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (q_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "            (out_proj): BFPLinear(in_features=512, out_features=512, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): BFPLinear(in_features=512, out_features=2048, bias=True)\n",
              "          (fc2): BFPLinear(in_features=2048, out_features=512, bias=True)\n",
              "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lm_head): BFPLinear(in_features=512, out_features=58101, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2.load_state_dict(torch.load(\"init.pth\"))\n",
        "model_2.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiZJGJR69R_F"
      },
      "outputs": [],
      "source": [
        "model_2 = model_2.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "d8d11b4329c44eb8aeea66b346aa79cb",
            "fd8b582a48594282aab7bc9b47ede09e",
            "ce52f88f00724643bf8bce6bb068c142",
            "918f68181a064294a9f3db4f1d52d5bd",
            "268cc5b3a34346638bf3730313bd674a",
            "1275ed48e22c47eba2592ba19c7fc51a",
            "b980912f34b64e36bd6224c2c95dbf9e",
            "52330d14b9e94ae59e19efa0c47833f9",
            "0d5fa548678c408d88240c9dd1be76da",
            "5feabe724d4f46d5892c80453d9a03a4",
            "cb3bc56a64464d2f94123c3bc98cccf4"
          ]
        },
        "id": "HbrBNXXI9aZy",
        "outputId": "8f887fa0-4b1b-4c48-d415-9db4561f9f96"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8d11b4329c44eb8aeea66b346aa79cb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/32 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "34.524361433422925"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_ids_2 = train_ids_2.to(device)\n",
        "train_labels_2 = train_labels_2.to(device)\n",
        "train_mask_2 = train_mask_2.to(device)\n",
        "val_ids_2 = val_ids_2.to(device)\n",
        "val_labels_2 = val_labels_2.to(device)\n",
        "val_mask_2 = val_mask_2.to(device)\n",
        "estimate_bleu(model_2, val_ids_2, val_labels_2, 16) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## To do: averaging functions"
      ],
      "metadata": {
        "id": "2h-9KbW9nL9X"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTXhDc4D8V9"
      },
      "source": [
        "## Continue training "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrN6-Ww_0wuL"
      },
      "outputs": [],
      "source": [
        "hist_1 = []\n",
        "hist_2 = []\n",
        "epochs = 3\n",
        "\n",
        "lr = 1e-4\n",
        "optimizer_1 = BFPAdam(model_1.parameters(), lr, **args)\n",
        "optimizer_2 = BFPAdam(model_2.parameters(), lr, **args)\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kk8IyQdZ8wT3"
      },
      "outputs": [],
      "source": [
        "bleu_1 = []\n",
        "bleu_2 = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN30vQ8FQf_p"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "IhDe8AO16UpE",
        "outputId": "297d6d65-a1fa-4129-8f70-c031a1e68d35"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    model_1.train()\n",
        "    model_2.train()\n",
        "    ind = np.arange(len(train_ids_1))\n",
        "    np.random.shuffle(ind)\n",
        "    prev_i = 0\n",
        "    for i in tqdm.notebook.tqdm(np.arange(batch_size, len(train_ids_1), batch_size)):\n",
        "        step = len(hist_1) + 1\n",
        "        batch_ind = ind[prev_i:i]\n",
        "        prev_i = i\n",
        "\n",
        "        # 1 model training\n",
        "        optimizer_1.zero_grad()\n",
        "        outputs_1 = model_1(input_ids=train_ids_1[batch_ind],\n",
        "                            labels=train_labels_1[batch_ind],\n",
        "                            attention_mask=train_mask_1[batch_ind])\n",
        "        loss_1 = outputs_1.loss\n",
        "        loss_1.backward()\n",
        "        optimizer_1.step()\n",
        "\n",
        "        hist_1.append(loss_1.item())\n",
        "\n",
        "        # 2 model training \n",
        "        optimizer_2.zero_grad()\n",
        "        outputs_2 = model_2(input_ids=train_ids_2[batch_ind],\n",
        "                            labels=train_labels_2[batch_ind],\n",
        "                            attention_mask=train_mask_2[batch_ind])\n",
        "        loss_2 = outputs_2.loss\n",
        "        loss_2.backward()\n",
        "        optimizer_2.step()\n",
        "\n",
        "        hist_2.append(loss_2.item())\n",
        "\n",
        "        # averaging parameters\n",
        "        if i % 1000 == 0:\n",
        "            # to do: BFP averaging!!!\n",
        "            for (param1, param2) in zip(model_1.parameters(), model_2.parameters()):\n",
        "                mean = (param1.data + param2.data) / 2\n",
        "                param1.data = param2.data = mean\n",
        "\n",
        "        # visualising training losses\n",
        "        if len(hist_1) % 10 == 0:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
        "\n",
        "            axs[0].plot(hist_1)\n",
        "            axs[0].set_xlabel(\"step\")\n",
        "            axs[0].set_ylabel(\"loss_1_model\")\n",
        "            \n",
        "            axs[1].plot(hist_2)\n",
        "            axs[1].set_xlabel(\"step\")\n",
        "            axs[1].set_ylabel(\"loss_2_model\")\n",
        "\n",
        "            plt.show()\n",
        "            \n",
        "    model_1.eval()\n",
        "    bleu_1.append(estimate_bleu(model_1, val_ids_1, val_labels_1, 16))\n",
        "    model_2.eval()\n",
        "    bleu_2.append(estimate_bleu(model_2, val_ids_2, val_labels_2, 16))        "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "quantization.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "004a41cfd22c418ca75ececfae791636": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0115d389c3b945cbabf8791625fc935b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02077c33037d473e8b1a824426924453": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "051c7f44da0c49cea5143bb70c5cb0b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "079b541cd84a442084c178fe2cf4b95b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33c4c536236846f7b03bdc512f42aa5e",
            "placeholder": "​",
            "style": "IPY_MODEL_929c37e79c2a47da815c8317eb8177f7",
            "value": "Downloading vocab.json: 100%"
          }
        },
        "0cd047fbd98a420ea34f292fe4149aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d5fa548678c408d88240c9dd1be76da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1275ed48e22c47eba2592ba19c7fc51a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14df44e474024c559f6a9fe8d784a1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c8997a4efc4125803c06ae4672456d",
            "max": 297928209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a476f8bdef374dc786459f1ec640dcf8",
            "value": 297928209
          }
        },
        "1612d3e4a0ff4b538dcf48c4acffcae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a3626487ced42d692089d5e4e4bc689": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c0a180df5424046a6959119f2f9cc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_262903e0b7254d7d8c07a4b512f2fc4d",
              "IPY_MODEL_14df44e474024c559f6a9fe8d784a1b8",
              "IPY_MODEL_7c576605bda34166a7eb14070151e8e6"
            ],
            "layout": "IPY_MODEL_68b078b37d6d4a96871f9f11e80d8c87"
          }
        },
        "1d09df3b7d344200bb93af88a3142c33": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f49e63af2c5403daf5f07cba4a57a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051c7f44da0c49cea5143bb70c5cb0b6",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a026113729465986e7c20e2d503d71",
            "value": " 778k/778k [00:00&lt;00:00, 1.61MB/s]"
          }
        },
        "262903e0b7254d7d8c07a4b512f2fc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d09df3b7d344200bb93af88a3142c33",
            "placeholder": "​",
            "style": "IPY_MODEL_0cd047fbd98a420ea34f292fe4149aae",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "268cc5b3a34346638bf3730313bd674a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "338f2533021448b5b1af11088eab81ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33c4c536236846f7b03bdc512f42aa5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353f49cc24f9425ea9464203ef85b3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "372d3e10b4624cabb53c4b9f0cc871a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7cd47ae9f045d39a84d03b2605ced5",
            "placeholder": "​",
            "style": "IPY_MODEL_d29bb1058e8d44c4a6b86cd2c175096b",
            "value": " 42.0/42.0 [00:00&lt;00:00, 719B/s]"
          }
        },
        "3742dfb846f74d639405a2d53c3c4949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f56deb7d6bd34becb83a7d30d5a173a8",
              "IPY_MODEL_ffa85f4bad2c48c58c8d60c4be519c54",
              "IPY_MODEL_41bd42171fc34b03a4170cc4610f8f28"
            ],
            "layout": "IPY_MODEL_8fbc76dd78fa4bfb845f12bf0a104b97"
          }
        },
        "3c46e3b7f2164b3f98ad8e4d903333f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1412309994a40b698d2b7371dbc498e",
            "max": 42,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6eda739bf78247f4b4667864da08b239",
            "value": 42
          }
        },
        "3f7ecb9dec8744218bf7c824ea05540a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41bd42171fc34b03a4170cc4610f8f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9648e0a2654c9d8cedda093d63529e",
            "placeholder": "​",
            "style": "IPY_MODEL_3f7ecb9dec8744218bf7c824ea05540a",
            "value": " 32/32 [06:06&lt;00:00, 10.37s/it]"
          }
        },
        "429318062e504b76bfc0e6d5834a7b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ffdd02b39341aab64eca07e493f90c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46054c74983a49e88144a2409de2c138": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "485902ad7f7a40d5acbbff77af093fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7887c8cb9d2498cbcc81b7bc606a035",
            "max": 1132,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43ffdd02b39341aab64eca07e493f90c",
            "value": 1132
          }
        },
        "4a673f4ca02d4474aca244abe3759b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b9f4cc7e5d34d80893e883646cf7df9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bfd878676ef4394a80b968e88a452ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52330d14b9e94ae59e19efa0c47833f9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5270f0f6e781400fbbfff34a3cd22bf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58e42271d8fb4eaba771b60681f1eee4",
              "IPY_MODEL_485902ad7f7a40d5acbbff77af093fc5",
              "IPY_MODEL_910db3428a514d31be8e309615619bbd"
            ],
            "layout": "IPY_MODEL_7cba82bedcf141ca97886e49597838b9"
          }
        },
        "55cfecb6d868450f825dd777c6a5e032": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69e493b07815487d993e40495b4aa953",
            "placeholder": "​",
            "style": "IPY_MODEL_b640b088f941453d9494428830535108",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "5869d43074c9413f8afbeb9200072c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6653e93147fd45e8ba50f51fffc35829",
            "placeholder": "​",
            "style": "IPY_MODEL_76d5984519194db69c6f27139ef06ad0",
            "value": "100%"
          }
        },
        "58e42271d8fb4eaba771b60681f1eee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855c3b46188244da87d7c837c385e453",
            "placeholder": "​",
            "style": "IPY_MODEL_1a3626487ced42d692089d5e4e4bc689",
            "value": "Downloading config.json: 100%"
          }
        },
        "59420f225f67442283ea71e81069257f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cb0f2ee33264b389917b828426d5ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d67c46261d8a4d20b4d06b1dddba7b31",
            "max": 796845,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_338f2533021448b5b1af11088eab81ae",
            "value": 796845
          }
        },
        "5d6b9ee0b5544b769cd366e873ed6006": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3c217e8a31c428288810e42695a32fe",
            "placeholder": "​",
            "style": "IPY_MODEL_99fd0972dab248449331e230b0ff4353",
            "value": "Downloading target.spm: 100%"
          }
        },
        "5feabe724d4f46d5892c80453d9a03a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6653e93147fd45e8ba50f51fffc35829": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68b078b37d6d4a96871f9f11e80d8c87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e493b07815487d993e40495b4aa953": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aeb67add48845da8aca416207f9e643": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_079b541cd84a442084c178fe2cf4b95b",
              "IPY_MODEL_759a8006daa64653a6f72822b9ddc6d7",
              "IPY_MODEL_c8a4a5377ce04df39311f4299651c2ce"
            ],
            "layout": "IPY_MODEL_75c666ab586a4c539d2211512aa8d650"
          }
        },
        "6dfeab4b232d4b90acb13053ae1d64d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5869d43074c9413f8afbeb9200072c7e",
              "IPY_MODEL_d67dcc7a11df4faf80c78cd509715377",
              "IPY_MODEL_b3bedfbab80d44f7b58f3cf41428a4f9"
            ],
            "layout": "IPY_MODEL_7a1500ff457646b4a773e94c9b29a48a"
          }
        },
        "6eda739bf78247f4b4667864da08b239": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "759a8006daa64653a6f72822b9ddc6d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea7d2bc3a9c469e83ca423a788fcc89",
            "max": 1273232,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02077c33037d473e8b1a824426924453",
            "value": 1273232
          }
        },
        "75c666ab586a4c539d2211512aa8d650": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d5984519194db69c6f27139ef06ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a1500ff457646b4a773e94c9b29a48a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c576605bda34166a7eb14070151e8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_004a41cfd22c418ca75ececfae791636",
            "placeholder": "​",
            "style": "IPY_MODEL_429318062e504b76bfc0e6d5834a7b14",
            "value": " 284M/284M [00:07&lt;00:00, 40.3MB/s]"
          }
        },
        "7cba82bedcf141ca97886e49597838b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "806e4cec94654450bdacc72b67b9d020": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "818cf962d7bd4cf994aaa803f10a7b5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "855c3b46188244da87d7c837c385e453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8896faaae6414f22a039b274d9735014": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8962b405e6644892b35863b3928077b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8fbc76dd78fa4bfb845f12bf0a104b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "910db3428a514d31be8e309615619bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bfd878676ef4394a80b968e88a452ee",
            "placeholder": "​",
            "style": "IPY_MODEL_99c4e4c9748e4b228105e7d4ac0dab95",
            "value": " 1.11k/1.11k [00:00&lt;00:00, 31.9kB/s]"
          }
        },
        "918f68181a064294a9f3db4f1d52d5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5feabe724d4f46d5892c80453d9a03a4",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3bc56a64464d2f94123c3bc98cccf4",
            "value": " 32/32 [00:32&lt;00:00,  1.05it/s]"
          }
        },
        "929c37e79c2a47da815c8317eb8177f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95a2ecfc0df14e07bb88195822180f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_55cfecb6d868450f825dd777c6a5e032",
              "IPY_MODEL_3c46e3b7f2164b3f98ad8e4d903333f4",
              "IPY_MODEL_372d3e10b4624cabb53c4b9f0cc871a1"
            ],
            "layout": "IPY_MODEL_f4fd7e11fb5542e49d4b09e42bce50c5"
          }
        },
        "99c4e4c9748e4b228105e7d4ac0dab95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99fd0972dab248449331e230b0ff4353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3559ec0193047ddb8059f9e77aa8ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46054c74983a49e88144a2409de2c138",
            "max": 768489,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db974521d21d42008eeeca003cdb2e94",
            "value": 768489
          }
        },
        "a476f8bdef374dc786459f1ec640dcf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aea7d2bc3a9c469e83ca423a788fcc89": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bedfbab80d44f7b58f3cf41428a4f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8896faaae6414f22a039b274d9735014",
            "placeholder": "​",
            "style": "IPY_MODEL_8962b405e6644892b35863b3928077b0",
            "value": " 32/32 [00:21&lt;00:00,  3.51it/s]"
          }
        },
        "b485bd40efe9497dbd405cd74fa7e163": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b48daac1c862478d9de878fecd1a01d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b640b088f941453d9494428830535108": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b980912f34b64e36bd6224c2c95dbf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5353d0cb3dd461aa18f1511ad7b17ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ad9d8f5a7c42299bf1254da4976411": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7f6ba6a8d7b4e4b8d0b3c9ad0fa03ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d6b9ee0b5544b769cd366e873ed6006",
              "IPY_MODEL_a3559ec0193047ddb8059f9e77aa8ccf",
              "IPY_MODEL_dc7ea4c6963b4c9f8df5c7f584ea2e50"
            ],
            "layout": "IPY_MODEL_806e4cec94654450bdacc72b67b9d020"
          }
        },
        "c8a4a5377ce04df39311f4299651c2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b485bd40efe9497dbd405cd74fa7e163",
            "placeholder": "​",
            "style": "IPY_MODEL_df08cf48d7264a96872c6b71de965d4a",
            "value": " 1.21M/1.21M [00:00&lt;00:00, 2.89MB/s]"
          }
        },
        "cb3bc56a64464d2f94123c3bc98cccf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce52f88f00724643bf8bce6bb068c142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52330d14b9e94ae59e19efa0c47833f9",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d5fa548678c408d88240c9dd1be76da",
            "value": 32
          }
        },
        "d1a026113729465986e7c20e2d503d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d29bb1058e8d44c4a6b86cd2c175096b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d67c46261d8a4d20b4d06b1dddba7b31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67dcc7a11df4faf80c78cd509715377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0115d389c3b945cbabf8791625fc935b",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_818cf962d7bd4cf994aaa803f10a7b5f",
            "value": 32
          }
        },
        "d8d11b4329c44eb8aeea66b346aa79cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd8b582a48594282aab7bc9b47ede09e",
              "IPY_MODEL_ce52f88f00724643bf8bce6bb068c142",
              "IPY_MODEL_918f68181a064294a9f3db4f1d52d5bd"
            ],
            "layout": "IPY_MODEL_268cc5b3a34346638bf3730313bd674a"
          }
        },
        "db974521d21d42008eeeca003cdb2e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dc7ea4c6963b4c9f8df5c7f584ea2e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59420f225f67442283ea71e81069257f",
            "placeholder": "​",
            "style": "IPY_MODEL_353f49cc24f9425ea9464203ef85b3b1",
            "value": " 750k/750k [00:00&lt;00:00, 3.42MB/s]"
          }
        },
        "df08cf48d7264a96872c6b71de965d4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3c217e8a31c428288810e42695a32fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7b2dd516bae41d598af21886c644818": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b9f4cc7e5d34d80893e883646cf7df9",
            "placeholder": "​",
            "style": "IPY_MODEL_1612d3e4a0ff4b538dcf48c4acffcae9",
            "value": "Downloading source.spm: 100%"
          }
        },
        "eba5e9bfb18440f3bcfe245c12d0cd0a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1412309994a40b698d2b7371dbc498e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fd7e11fb5542e49d4b09e42bce50c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f56deb7d6bd34becb83a7d30d5a173a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba5e9bfb18440f3bcfe245c12d0cd0a",
            "placeholder": "​",
            "style": "IPY_MODEL_b48daac1c862478d9de878fecd1a01d4",
            "value": "100%"
          }
        },
        "f7887c8cb9d2498cbcc81b7bc606a035": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c8997a4efc4125803c06ae4672456d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8b582a48594282aab7bc9b47ede09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1275ed48e22c47eba2592ba19c7fc51a",
            "placeholder": "​",
            "style": "IPY_MODEL_b980912f34b64e36bd6224c2c95dbf9e",
            "value": "100%"
          }
        },
        "fe114834509f4b53b21f741b42ced760": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7b2dd516bae41d598af21886c644818",
              "IPY_MODEL_5cb0f2ee33264b389917b828426d5ca9",
              "IPY_MODEL_1f49e63af2c5403daf5f07cba4a57a96"
            ],
            "layout": "IPY_MODEL_c7ad9d8f5a7c42299bf1254da4976411"
          }
        },
        "fe9648e0a2654c9d8cedda093d63529e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff7cd47ae9f045d39a84d03b2605ced5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa85f4bad2c48c58c8d60c4be519c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5353d0cb3dd461aa18f1511ad7b17ed",
            "max": 32,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a673f4ca02d4474aca244abe3759b6c",
            "value": 32
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}